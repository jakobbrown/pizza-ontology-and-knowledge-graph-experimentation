{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invisible-surrey",
   "metadata": {},
   "source": [
    "# 2.6 Ontology Embeddings (Task Vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-finnish",
   "metadata": {},
   "source": [
    "### Subtask Vector.1 Run OWL2Vec* with the created ontology and generated data. Test three different configurations. Save the generated vectors in both binary and textual format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-kidney",
   "metadata": {},
   "source": [
    "#### Config 1.\n",
    "\n",
    "configuration settings: Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "employed-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: There are 302 triples in the ontology\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.05426287651062012 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.01941680908203125 seconds \n",
      "INFO: \tExtracting class membership triples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Access the ontology ...\n",
      "\n",
      "Calculate the ontology projection ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \t\tTime extracting class membership: 0.13052010536193848 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.008331060409545898 seconds \n",
      "INFO: \tExtracting triples associated to Has_base\n",
      "INFO: \t\tTime extracting triples for property: 0.15897607803344727 seconds \n",
      "INFO: \tExtracting triples associated to Has_ingredient\n",
      "INFO: \t\tTime extracting triples for property: 0.15742897987365723 seconds \n",
      "INFO: \tExtracting triples associated to Has_location\n",
      "INFO: \t\tTime extracting triples for property: 0.17687296867370605 seconds \n",
      "INFO: \tExtracting triples associated to Has_topping\n",
      "INFO: \t\tTime extracting triples for property: 0.17138409614562988 seconds \n",
      "INFO: \tExtracting triples associated to Is_base_of\n",
      "INFO: \t\tTime extracting triples for property: 0.16196084022521973 seconds \n",
      "INFO: \tExtracting triples associated to Is_ingredient_of\n",
      "INFO: \t\tTime extracting triples for property: 0.15981292724609375 seconds \n",
      "INFO: \tExtracting triples associated to Is_located_in\n",
      "INFO: \t\tTime extracting triples for property: 0.15961289405822754 seconds \n",
      "INFO: \tExtracting triples associated to Is_topping_of\n",
      "INFO: \t\tTime extracting triples for property: 0.1613149642944336 seconds \n",
      "INFO: \tExtracting triples associated to Served_at\n",
      "INFO: \t\tTime extracting triples for property: 0.1302938461303711 seconds \n",
      "INFO: \tExtracting triples associated to Serves\n",
      "INFO: \t\tTime extracting triples for property: 0.12637090682983398 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.16259098052978516 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 0.2962300777435303 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.11532902717590332 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract classes and individuals ...\n",
      "\n",
      "Extract axioms ...\n",
      "\n",
      "Extract annotations ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: collected 210 word types from a corpus of 12418 raw words and 2356 sentences\n",
      "INFO: Loading a fresh vocabulary\n",
      "INFO: effective_min_count=1 retains 210 unique words (100% of original 210, drops 0)\n",
      "INFO: effective_min_count=1 leaves 12418 word corpus (100% of original 12418, drops 0)\n",
      "INFO: deleting the raw counts dictionary of 210 items\n",
      "INFO: sample=0.001 downsamples 80 most-common words\n",
      "INFO: downsampling leaves estimated 5154 word corpus (41.5% of prior 12418)\n",
      "INFO: estimated required memory for 210 words and 100 dimensions: 273000 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: training model with 4 workers on 210 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate URI document ...\n",
      "Extracted 716 walks for 50 seed entities\n",
      "Extracted 67 axiom sentences\n",
      "\n",
      "Generate literal document ...\n",
      "Extracted 7 annotation sentences\n",
      "\n",
      "Generate mixture document ...\n",
      "URI_Doc: 783, Lit_Doc: 790, Mix_Doc: 783\n",
      "Time for document construction: 2.771167039871216 seconds\n",
      "\n",
      "Train the language model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 12418 raw words (5143 effective words) took 0.0s, 130017 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 12418 raw words (5188 effective words) took 0.1s, 88657 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 12418 raw words (5125 effective words) took 0.0s, 166160 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 12418 raw words (5205 effective words) took 0.0s, 153905 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 12418 raw words (5156 effective words) took 0.0s, 149504 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 12418 raw words (5143 effective words) took 0.0s, 137734 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 12418 raw words (5042 effective words) took 0.0s, 139902 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 12418 raw words (5166 effective words) took 0.0s, 135196 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 12418 raw words (5105 effective words) took 0.0s, 148317 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 12418 raw words (5137 effective words) took 0.0s, 156455 effective words/s\n",
      "INFO: training on a 124180 raw words (51410 effective words) took 0.5s, 112502 effective words/s\n",
      "WARNING: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "INFO: saving Word2Vec object under ./output_embedding/created_ontology.embeddings, separately None\n",
      "INFO: not storing attribute vectors_norm\n",
      "INFO: not storing attribute cum_table\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: saved ./output_embedding/created_ontology.embeddings\n",
      "INFO: storing 210x100 projection weights into ./output_embedding/created_ontology.embeddings.txt\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings.txt', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: storing 210x100 projection weights into ./output_embedding/created_ontology.embeddings.bin\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings.bin', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for learning the language model: 0.596937894821167 seconds\n",
      "Model saved. Done!\n"
     ]
    }
   ],
   "source": [
    "# using lab 9 code, below code being straight from OWl2Vec_Standalone.py\n",
    "# running on base_ontology.owl\n",
    "# embedding_dir = ./output_embedding/created_ontology.embeddings\n",
    "# config 1 - default OWL2vec* setting\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import configparser\n",
    "\n",
    "sys.path.append('./rdf2vec/')\n",
    "sys.path.append('./lib/')\n",
    "from RDF2Vec_Embed import get_rdf2vec_walks\n",
    "from Label import pre_process_words, URI_parse\n",
    "from Onto_Projection import Reasoner, OntologyProjection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--ontology_file\", type=str, default=None, help=\"The input ontology for embedding\")\n",
    "parser.add_argument(\"--embedding_dir\", type=str, default=None, help=\"The output embedding directory\")\n",
    "parser.add_argument(\"--config_file\", type=str, default='default.cfg', help=\"Configuration file\")\n",
    "parser.add_argument(\"--URI_Doc\", help=\"Using URI document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Lit_Doc\", help=\"Using literal document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Mix_Doc\", help=\"Using mixture document\", action=\"store_true\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# read and combine configurations\n",
    "# overwrite the parameters in the configuration file by the command parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.read(FLAGS.config_file)\n",
    "if FLAGS.ontology_file is not None:\n",
    "    config['BASIC']['ontology_file'] = FLAGS.ontology_file\n",
    "if FLAGS.embedding_dir is not None:\n",
    "    config['BASIC']['embedding_dir'] = FLAGS.embedding_dir\n",
    "if FLAGS.URI_Doc:\n",
    "    config['DOCUMENT']['URI_Doc'] = 'yes'\n",
    "if FLAGS.Lit_Doc:\n",
    "    config['DOCUMENT']['Lit_Doc'] = 'yes'\n",
    "if FLAGS.Mix_Doc:\n",
    "    config['DOCUMENT']['Mix_Doc'] = 'yes'\n",
    "if 'cache_dir' not in config['DOCUMENT']:\n",
    "    config['DOCUMENT']['cache_dir'] = './cache'\n",
    "if 'embedding_dir' not in config['BASIC']:\n",
    "    config['BASIC']['embedding_dir'] = os.path.join(config['DOCUMENT']['cache_dir'], 'output')\n",
    "\n",
    "start_time = time.time()\n",
    "if ('ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes') or \\\n",
    "        'pre_entity_file' not in config['DOCUMENT'] or 'pre_axiom_file' not in config['DOCUMENT'] or \\\n",
    "        'pre_annotation_file' not in config['DOCUMENT']:\n",
    "    print('\\n Access the ontology ...')\n",
    "    projection = OntologyProjection(config['BASIC']['ontology_file'], reasoner=Reasoner.STRUCTURAL, only_taxonomy=False,\n",
    "                                    bidirectional_taxonomy=True, include_literals=True, avoid_properties=set(),\n",
    "                                    additional_preferred_labels_annotations=set(),\n",
    "                                    additional_synonyms_annotations=set(),\n",
    "                                    memory_reasoner='13351')\n",
    "else:\n",
    "    projection = None\n",
    "\n",
    "# Ontology projection\n",
    "if 'ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes':\n",
    "    print('\\nCalculate the ontology projection ...')\n",
    "    projection.extractProjection()\n",
    "    onto_projection_file = os.path.join(config['DOCUMENT']['cache_dir'], 'projection.ttl')\n",
    "    projection.saveProjectionGraph(onto_projection_file)\n",
    "    ontology_file = onto_projection_file\n",
    "else:\n",
    "    ontology_file = config['BASIC']['ontology_file']\n",
    "\n",
    "# Extract and save seed entities (classes and individuals)\n",
    "# Or read entities specified by the user\n",
    "if 'pre_entity_file' in config['DOCUMENT']:\n",
    "    entities = [line.strip() for line in open(config['DOCUMENT']['pre_entity_file']).readlines()]\n",
    "else:\n",
    "    print('\\nExtract classes and individuals ...')\n",
    "    projection.extractEntityURIs()\n",
    "    classes = projection.getClassURIs()\n",
    "    individuals = projection.getIndividualURIs()\n",
    "    entities = classes.union(individuals)\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'entities.txt'), 'w') as f:\n",
    "        for e in entities:\n",
    "            f.write('%s\\n' % e)\n",
    "\n",
    "# Extract axioms in Manchester Syntax if it is not pre_axiom_file is not set\n",
    "if 'pre_axiom_file' not in config['DOCUMENT']:\n",
    "    print('\\nExtract axioms ...')\n",
    "    projection.createManchesterSyntaxAxioms()\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt'), 'w') as f:\n",
    "        for ax in projection.axioms_manchester:\n",
    "            f.write('%s\\n' % ax)\n",
    "\n",
    "# If pre_annotation_file is set, directly read annotations\n",
    "# else, read annotations including rdfs:label and other literals from the ontology\n",
    "#   Extract annotations: 1) English label of each entity, by rdfs:label or skos:preferredLabel\n",
    "#                        2) None label annotations as sentences of the literal document\n",
    "uri_label, annotations = dict(), list()\n",
    "\n",
    "if 'pre_annotation_file' in config['DOCUMENT']:\n",
    "    with open(config['DOCUMENT']['pre_annotation_file']) as f:\n",
    "        for line in f.readlines():\n",
    "            tmp = line.strip().split()\n",
    "            if tmp[1] == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "                uri_label[tmp[0]] = pre_process_words(tmp[2:])\n",
    "            else:\n",
    "                annotations.append([tmp[0]] + tmp[2:])\n",
    "\n",
    "else:\n",
    "    print('\\nExtract annotations ...')\n",
    "    projection.indexAnnotations()\n",
    "    for e in entities:\n",
    "        if e in projection.entityToPreferredLabels and len(projection.entityToPreferredLabels[e]) > 0:\n",
    "            label = list(projection.entityToPreferredLabels[e])[0]\n",
    "            uri_label[e] = pre_process_words(words=label.split())\n",
    "    for e in entities:\n",
    "        if e in projection.entityToAllLexicalLabels:\n",
    "            for v in projection.entityToAllLexicalLabels[e]:\n",
    "                if (v is not None) and \\\n",
    "                        (not (e in projection.entityToPreferredLabels and v in projection.entityToPreferredLabels[e])):\n",
    "                    annotation = [e] + v.split()\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'annotations.txt'), 'w') as f:\n",
    "        for e in projection.entityToPreferredLabels:\n",
    "            for v in projection.entityToPreferredLabels[e]:\n",
    "                f.write('%s preferred_label %s\\n' % (e, v))\n",
    "        for a in annotations:\n",
    "            f.write('%s\\n' % ' '.join(a))\n",
    "\n",
    "\n",
    "# read URI document\n",
    "# two parts: walks, axioms (if the axiom file exists)\n",
    "walk_sentences, axiom_sentences, URI_Doc = list(), list(), list()\n",
    "if 'URI_Doc' in config['DOCUMENT'] and config['DOCUMENT']['URI_Doc'] == 'yes':\n",
    "    print('\\nGenerate URI document ...')\n",
    "    #walker_type=config['DOCUMENT']['walker']\n",
    "    walks_ = get_rdf2vec_walks(onto_file=ontology_file, walker_type=config['DOCUMENT']['walker'],\n",
    "                               walk_depth=int(config['DOCUMENT']['walk_depth']), classes=entities)\n",
    "    print('Extracted %d walks for %d seed entities' % (len(walks_), len(entities)))\n",
    "    walk_sentences += [list(map(str, x)) for x in walks_]\n",
    "\n",
    "    axiom_file = os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt')\n",
    "    if os.path.exists(axiom_file):\n",
    "        for line in open(axiom_file).readlines():\n",
    "            axiom_sentence = [item for item in line.strip().split()]\n",
    "            axiom_sentences.append(axiom_sentence)\n",
    "    print('Extracted %d axiom sentences' % len(axiom_sentences))\n",
    "    URI_Doc = walk_sentences + axiom_sentences\n",
    "\n",
    "\n",
    "# Some entities have English labels\n",
    "# Keep the name of built-in properties (those starting with http://www.w3.org)\n",
    "# Some entities have no labels, then use the words in their URI name\n",
    "def label_item(item):\n",
    "    if item in uri_label:\n",
    "        return uri_label[item]\n",
    "    elif item.startswith('http://www.w3.org'):\n",
    "        return [item.split('#')[1].lower()]\n",
    "    elif item.startswith('http://'):\n",
    "        return URI_parse(uri=item)\n",
    "    else:\n",
    "        return [item.lower()]\n",
    "\n",
    "\n",
    "# read literal document\n",
    "# two parts: literals in the annotations (subject's label + literal words)\n",
    "#            replacing walk/axiom sentences by words in their labels\n",
    "Lit_Doc = list()\n",
    "if 'Lit_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Lit_Doc'] == 'yes':\n",
    "    print('\\nGenerate literal document ...')\n",
    "    for annotation in annotations:\n",
    "        processed_words = pre_process_words(annotation[1:])\n",
    "        if len(processed_words) > 0:\n",
    "            Lit_Doc.append(label_item(item=annotation[0]) + processed_words)\n",
    "    print('Extracted %d annotation sentences' % len(Lit_Doc))\n",
    "\n",
    "    for sentence in walk_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "    for sentence in axiom_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "# read mixture document\n",
    "# for each axiom/walk sentence, all): for each entity, keep its entity URI, replace the others by label words\n",
    "#                            random): randomly select one entity, keep its entity URI, replace the others by label words\n",
    "Mix_Doc = list()\n",
    "if 'Mix_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Mix_Doc'] == 'yes':\n",
    "    print('\\nGenerate mixture document ...')\n",
    "    for sentence in walk_sentences + axiom_sentences:\n",
    "        if config['DOCUMENT']['Mix_Type'] == 'all':\n",
    "            for index in range(len(sentence)):\n",
    "                mix_sentence = list()\n",
    "                for i, item in enumerate(sentence):\n",
    "                    mix_sentence += [item] if i == index else label_item(item=item)\n",
    "                Mix_Doc.append(mix_sentence)\n",
    "        elif config['DOCUMENT']['Mix_Type'] == 'random':\n",
    "            random_index = random.randint(0, len(sentence) - 1)\n",
    "            mix_sentence = list()\n",
    "            for i, item in enumerate(sentence):\n",
    "                mix_sentence += [item] if i == random_index else label_item(item=item)\n",
    "            Mix_Doc.append(mix_sentence)\n",
    "\n",
    "print('URI_Doc: %d, Lit_Doc: %d, Mix_Doc: %d' % (len(URI_Doc), len(Lit_Doc), len(Mix_Doc)))\n",
    "all_doc = URI_Doc + Lit_Doc + Mix_Doc\n",
    "\n",
    "\n",
    "print('Time for document construction: %s seconds' % (time.time() - start_time))\n",
    "random.shuffle(all_doc)\n",
    "\n",
    "\n",
    "#Save all_doc\n",
    "with open(os.path.join(config['DOCUMENT']['cache_dir'], 'document_sentences.txt'), 'w') as f:\n",
    "    for sentence in all_doc:\n",
    "        for w in sentence:\n",
    "            f.write('%s ' % w)\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# learn the language model (train a new model or fine tune the pre-trained model)\n",
    "start_time = time.time()\n",
    "if 'pre_train_model' not in config['MODEL'] or not os.path.exists(config['MODEL']['pre_train_model']):\n",
    "    print('\\nTrain the language model ...')\n",
    "    model_ = gensim.models.Word2Vec(all_doc, size=int(config['MODEL']['embed_size']),\n",
    "                                    window=int(config['MODEL']['window']),\n",
    "                                    workers=multiprocessing.cpu_count(),\n",
    "                                    sg=1, iter=int(config['MODEL']['iteration']),\n",
    "                                    negative=int(config['MODEL']['negative']),\n",
    "                                    min_count=int(config['MODEL']['min_count']), seed=int(config['MODEL']['seed']))\n",
    "else:\n",
    "    print('\\nFine-tune the pre-trained language model ...')\n",
    "    model_ = gensim.models.Word2Vec.load(config['MODEL']['pre_train_model'])\n",
    "    if len(all_doc) > 0:\n",
    "        model_.min_count = int(config['MODEL']['min_count'])\n",
    "        model_.build_vocab(all_doc, update=True)\n",
    "        model_.train(all_doc, total_examples=model_.corpus_count, epochs=int(config['MODEL']['epoch']))\n",
    "\n",
    "model_.save(config['BASIC']['embedding_dir'])\n",
    "\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\".txt\", binary=False)\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\".bin\", binary=True)\n",
    "\n",
    "print('Time for learning the language model: %s seconds' % (time.time() - start_time))\n",
    "print('Model saved. Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-possession",
   "metadata": {},
   "source": [
    "#### config 2.\n",
    "\n",
    "Owl2vec* configuration changes:\n",
    "\n",
    "> walker = wl\n",
    "\n",
    "> walk depth = 2\n",
    "\n",
    "Embeddings saved with \"2\" at the end of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "formal-timing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: There are 302 triples in the ontology\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.06309795379638672 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.021349191665649414 seconds \n",
      "INFO: \tExtracting class membership triples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Access the ontology ...\n",
      "\n",
      "Calculate the ontology projection ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \t\tTime extracting class membership: 0.12949681282043457 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.008658885955810547 seconds \n",
      "INFO: \tExtracting triples associated to Has_base\n",
      "INFO: \t\tTime extracting triples for property: 0.13617682456970215 seconds \n",
      "INFO: \tExtracting triples associated to Has_ingredient\n",
      "INFO: \t\tTime extracting triples for property: 0.13710308074951172 seconds \n",
      "INFO: \tExtracting triples associated to Has_location\n",
      "INFO: \t\tTime extracting triples for property: 0.21639418601989746 seconds \n",
      "INFO: \tExtracting triples associated to Has_topping\n",
      "INFO: \t\tTime extracting triples for property: 0.16829490661621094 seconds \n",
      "INFO: \tExtracting triples associated to Is_base_of\n",
      "INFO: \t\tTime extracting triples for property: 0.15784287452697754 seconds \n",
      "INFO: \tExtracting triples associated to Is_ingredient_of\n",
      "INFO: \t\tTime extracting triples for property: 0.1461331844329834 seconds \n",
      "INFO: \tExtracting triples associated to Is_located_in\n",
      "INFO: \t\tTime extracting triples for property: 0.16029810905456543 seconds \n",
      "INFO: \tExtracting triples associated to Is_topping_of\n",
      "INFO: \t\tTime extracting triples for property: 0.11688709259033203 seconds \n",
      "INFO: \tExtracting triples associated to Served_at\n",
      "INFO: \t\tTime extracting triples for property: 0.12024307250976562 seconds \n",
      "INFO: \tExtracting triples associated to Serves\n",
      "INFO: \t\tTime extracting triples for property: 0.1331491470336914 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.13273906707763672 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 0.2458512783050537 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.08623003959655762 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract classes and individuals ...\n",
      "\n",
      "Extract axioms ...\n",
      "\n",
      "Extract annotations ...\n",
      "\n",
      "Generate URI document ...\n",
      "Extracted 815 walks for 50 seed entities\n",
      "Extracted 67 axiom sentences\n",
      "\n",
      "Generate literal document ...\n",
      "Extracted 7 annotation sentences\n",
      "\n",
      "Generate mixture document ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: collected 820 word types from a corpus of 8748 raw words and 2653 sentences\n",
      "INFO: Loading a fresh vocabulary\n",
      "INFO: effective_min_count=1 retains 820 unique words (100% of original 820, drops 0)\n",
      "INFO: effective_min_count=1 leaves 8748 word corpus (100% of original 8748, drops 0)\n",
      "INFO: deleting the raw counts dictionary of 820 items\n",
      "INFO: sample=0.001 downsamples 64 most-common words\n",
      "INFO: downsampling leaves estimated 4930 word corpus (56.4% of prior 8748)\n",
      "INFO: estimated required memory for 820 words and 100 dimensions: 1066000 bytes\n",
      "INFO: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "URI_Doc: 882, Lit_Doc: 889, Mix_Doc: 882\n",
      "Time for document construction: 2.684782028198242 seconds\n",
      "\n",
      "Train the language model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: training model with 4 workers on 820 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 8748 raw words (4926 effective words) took 0.0s, 166259 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 8748 raw words (4869 effective words) took 0.0s, 165837 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 8748 raw words (4954 effective words) took 0.0s, 157477 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 8748 raw words (4930 effective words) took 0.0s, 166616 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 8748 raw words (4880 effective words) took 0.0s, 143266 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 8748 raw words (4911 effective words) took 0.0s, 144581 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 8748 raw words (4905 effective words) took 0.0s, 148010 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 8748 raw words (4900 effective words) took 0.0s, 146996 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 8748 raw words (4905 effective words) took 0.0s, 136899 effective words/s\n",
      "DEBUG: job loop exiting, total 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 8748 raw words (4869 effective words) took 0.0s, 151445 effective words/s\n",
      "INFO: training on a 87480 raw words (49049 effective words) took 0.4s, 116728 effective words/s\n",
      "WARNING: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "INFO: saving Word2Vec object under ./output_embedding/created_ontology.embeddings2, separately None\n",
      "INFO: not storing attribute vectors_norm\n",
      "INFO: not storing attribute cum_table\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings2', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: saved ./output_embedding/created_ontology.embeddings2\n",
      "INFO: storing 820x100 projection weights into ./output_embedding/created_ontology.embeddings2.txt\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings2.txt', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: storing 820x100 projection weights into ./output_embedding/created_ontology.embeddings2.bin\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings2.bin', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for learning the language model: 0.7870798110961914 seconds\n",
      "Model saved. Done!\n"
     ]
    }
   ],
   "source": [
    "# using lab 9 code, below code being straight from OWl2Vec_Standalone.py\n",
    "# running on ontology_with_data\n",
    "# embedding_dir = ./output_embedding2/created_ontology.embeddings\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import configparser\n",
    "\n",
    "sys.path.append('./rdf2vec/')\n",
    "sys.path.append('./lib/')\n",
    "from RDF2Vec_Embed import get_rdf2vec_walks\n",
    "from Label import pre_process_words, URI_parse\n",
    "from Onto_Projection import Reasoner, OntologyProjection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--ontology_file\", type=str, default=None, help=\"The input ontology for embedding\")\n",
    "parser.add_argument(\"--embedding_dir\", type=str, default=None, help=\"The output embedding directory\")\n",
    "parser.add_argument(\"--config_file\", type=str, default='default.cfg', help=\"Configuration file\")\n",
    "parser.add_argument(\"--URI_Doc\", help=\"Using URI document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Lit_Doc\", help=\"Using literal document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Mix_Doc\", help=\"Using mixture document\", action=\"store_true\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# read and combine configurations\n",
    "# overwrite the parameters in the configuration file by the command parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.read(FLAGS.config_file)\n",
    "if FLAGS.ontology_file is not None:\n",
    "    config['BASIC']['ontology_file'] = FLAGS.ontology_file\n",
    "if FLAGS.embedding_dir is not None:\n",
    "    config['BASIC']['embedding_dir'] = FLAGS.embedding_dir\n",
    "if FLAGS.URI_Doc:\n",
    "    config['DOCUMENT']['URI_Doc'] = 'yes'\n",
    "if FLAGS.Lit_Doc:\n",
    "    config['DOCUMENT']['Lit_Doc'] = 'yes'\n",
    "if FLAGS.Mix_Doc:\n",
    "    config['DOCUMENT']['Mix_Doc'] = 'yes'\n",
    "if 'cache_dir' not in config['DOCUMENT']:\n",
    "    config['DOCUMENT']['cache_dir'] = './cache'\n",
    "if 'embedding_dir' not in config['BASIC']:\n",
    "    config['BASIC']['embedding_dir'] = os.path.join(config['DOCUMENT']['cache_dir'], 'output')\n",
    "\n",
    "start_time = time.time()\n",
    "if ('ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes') or \\\n",
    "        'pre_entity_file' not in config['DOCUMENT'] or 'pre_axiom_file' not in config['DOCUMENT'] or \\\n",
    "        'pre_annotation_file' not in config['DOCUMENT']:\n",
    "    print('\\n Access the ontology ...')\n",
    "    projection = OntologyProjection(config['BASIC']['ontology_file'], reasoner=Reasoner.STRUCTURAL, only_taxonomy=False,\n",
    "                                    bidirectional_taxonomy=True, include_literals=True, avoid_properties=set(),\n",
    "                                    additional_preferred_labels_annotations=set(),\n",
    "                                    additional_synonyms_annotations=set(),\n",
    "                                    memory_reasoner='13351')\n",
    "else:\n",
    "    projection = None\n",
    "\n",
    "# Ontology projection\n",
    "if 'ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes':\n",
    "    print('\\nCalculate the ontology projection ...')\n",
    "    projection.extractProjection()\n",
    "    onto_projection_file = os.path.join(config['DOCUMENT']['cache_dir'], 'projection.ttl')\n",
    "    projection.saveProjectionGraph(onto_projection_file)\n",
    "    ontology_file = onto_projection_file\n",
    "else:\n",
    "    ontology_file = config['BASIC']['ontology_file']\n",
    "\n",
    "# Extract and save seed entities (classes and individuals)\n",
    "# Or read entities specified by the user\n",
    "if 'pre_entity_file' in config['DOCUMENT']:\n",
    "    entities = [line.strip() for line in open(config['DOCUMENT']['pre_entity_file']).readlines()]\n",
    "else:\n",
    "    print('\\nExtract classes and individuals ...')\n",
    "    projection.extractEntityURIs()\n",
    "    classes = projection.getClassURIs()\n",
    "    individuals = projection.getIndividualURIs()\n",
    "    entities = classes.union(individuals)\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'entities.txt'), 'w') as f:\n",
    "        for e in entities:\n",
    "            f.write('%s\\n' % e)\n",
    "\n",
    "# Extract axioms in Manchester Syntax if it is not pre_axiom_file is not set\n",
    "if 'pre_axiom_file' not in config['DOCUMENT']:\n",
    "    print('\\nExtract axioms ...')\n",
    "    projection.createManchesterSyntaxAxioms()\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt'), 'w') as f:\n",
    "        for ax in projection.axioms_manchester:\n",
    "            f.write('%s\\n' % ax)\n",
    "\n",
    "# If pre_annotation_file is set, directly read annotations\n",
    "# else, read annotations including rdfs:label and other literals from the ontology\n",
    "#   Extract annotations: 1) English label of each entity, by rdfs:label or skos:preferredLabel\n",
    "#                        2) None label annotations as sentences of the literal document\n",
    "uri_label, annotations = dict(), list()\n",
    "\n",
    "if 'pre_annotation_file' in config['DOCUMENT']:\n",
    "    with open(config['DOCUMENT']['pre_annotation_file']) as f:\n",
    "        for line in f.readlines():\n",
    "            tmp = line.strip().split()\n",
    "            if tmp[1] == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "                uri_label[tmp[0]] = pre_process_words(tmp[2:])\n",
    "            else:\n",
    "                annotations.append([tmp[0]] + tmp[2:])\n",
    "\n",
    "else:\n",
    "    print('\\nExtract annotations ...')\n",
    "    projection.indexAnnotations()\n",
    "    for e in entities:\n",
    "        if e in projection.entityToPreferredLabels and len(projection.entityToPreferredLabels[e]) > 0:\n",
    "            label = list(projection.entityToPreferredLabels[e])[0]\n",
    "            uri_label[e] = pre_process_words(words=label.split())\n",
    "    for e in entities:\n",
    "        if e in projection.entityToAllLexicalLabels:\n",
    "            for v in projection.entityToAllLexicalLabels[e]:\n",
    "                if (v is not None) and \\\n",
    "                        (not (e in projection.entityToPreferredLabels and v in projection.entityToPreferredLabels[e])):\n",
    "                    annotation = [e] + v.split()\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'annotations.txt'), 'w') as f:\n",
    "        for e in projection.entityToPreferredLabels:\n",
    "            for v in projection.entityToPreferredLabels[e]:\n",
    "                f.write('%s preferred_label %s\\n' % (e, v))\n",
    "        for a in annotations:\n",
    "            f.write('%s\\n' % ' '.join(a))\n",
    "\n",
    "\n",
    "# read URI document\n",
    "# two parts: walks, axioms (if the axiom file exists)\n",
    "walk_sentences, axiom_sentences, URI_Doc = list(), list(), list()\n",
    "if 'URI_Doc' in config['DOCUMENT'] and config['DOCUMENT']['URI_Doc'] == 'yes':\n",
    "    print('\\nGenerate URI document ...')\n",
    "    #walker_type=config['DOCUMENT']['walker']\n",
    "    walks_ = get_rdf2vec_walks(onto_file=ontology_file, walker_type=config['DOCUMENT']['walker'],\n",
    "                               walk_depth=int(config['DOCUMENT']['walk_depth']), classes=entities)\n",
    "    print('Extracted %d walks for %d seed entities' % (len(walks_), len(entities)))\n",
    "    walk_sentences += [list(map(str, x)) for x in walks_]\n",
    "\n",
    "    axiom_file = os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt')\n",
    "    if os.path.exists(axiom_file):\n",
    "        for line in open(axiom_file).readlines():\n",
    "            axiom_sentence = [item for item in line.strip().split()]\n",
    "            axiom_sentences.append(axiom_sentence)\n",
    "    print('Extracted %d axiom sentences' % len(axiom_sentences))\n",
    "    URI_Doc = walk_sentences + axiom_sentences\n",
    "\n",
    "\n",
    "# Some entities have English labels\n",
    "# Keep the name of built-in properties (those starting with http://www.w3.org)\n",
    "# Some entities have no labels, then use the words in their URI name\n",
    "def label_item(item):\n",
    "    if item in uri_label:\n",
    "        return uri_label[item]\n",
    "    elif item.startswith('http://www.w3.org'):\n",
    "        return [item.split('#')[1].lower()]\n",
    "    elif item.startswith('http://'):\n",
    "        return URI_parse(uri=item)\n",
    "    else:\n",
    "        return [item.lower()]\n",
    "\n",
    "\n",
    "# read literal document\n",
    "# two parts: literals in the annotations (subject's label + literal words)\n",
    "#            replacing walk/axiom sentences by words in their labels\n",
    "Lit_Doc = list()\n",
    "if 'Lit_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Lit_Doc'] == 'yes':\n",
    "    print('\\nGenerate literal document ...')\n",
    "    for annotation in annotations:\n",
    "        processed_words = pre_process_words(annotation[1:])\n",
    "        if len(processed_words) > 0:\n",
    "            Lit_Doc.append(label_item(item=annotation[0]) + processed_words)\n",
    "    print('Extracted %d annotation sentences' % len(Lit_Doc))\n",
    "\n",
    "    for sentence in walk_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "    for sentence in axiom_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "# read mixture document\n",
    "# for each axiom/walk sentence, all): for each entity, keep its entity URI, replace the others by label words\n",
    "#                            random): randomly select one entity, keep its entity URI, replace the others by label words\n",
    "Mix_Doc = list()\n",
    "if 'Mix_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Mix_Doc'] == 'yes':\n",
    "    print('\\nGenerate mixture document ...')\n",
    "    for sentence in walk_sentences + axiom_sentences:\n",
    "        if config['DOCUMENT']['Mix_Type'] == 'all':\n",
    "            for index in range(len(sentence)):\n",
    "                mix_sentence = list()\n",
    "                for i, item in enumerate(sentence):\n",
    "                    mix_sentence += [item] if i == index else label_item(item=item)\n",
    "                Mix_Doc.append(mix_sentence)\n",
    "        elif config['DOCUMENT']['Mix_Type'] == 'random':\n",
    "            random_index = random.randint(0, len(sentence) - 1)\n",
    "            mix_sentence = list()\n",
    "            for i, item in enumerate(sentence):\n",
    "                mix_sentence += [item] if i == random_index else label_item(item=item)\n",
    "            Mix_Doc.append(mix_sentence)\n",
    "\n",
    "print('URI_Doc: %d, Lit_Doc: %d, Mix_Doc: %d' % (len(URI_Doc), len(Lit_Doc), len(Mix_Doc)))\n",
    "all_doc = URI_Doc + Lit_Doc + Mix_Doc\n",
    "\n",
    "\n",
    "print('Time for document construction: %s seconds' % (time.time() - start_time))\n",
    "random.shuffle(all_doc)\n",
    "\n",
    "\n",
    "#Save all_doc\n",
    "with open(os.path.join(config['DOCUMENT']['cache_dir'], 'document_sentences.txt'), 'w') as f:\n",
    "    for sentence in all_doc:\n",
    "        for w in sentence:\n",
    "            f.write('%s ' % w)\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# learn the language model (train a new model or fine tune the pre-trained model)\n",
    "start_time = time.time()\n",
    "if 'pre_train_model' not in config['MODEL'] or not os.path.exists(config['MODEL']['pre_train_model']):\n",
    "    print('\\nTrain the language model ...')\n",
    "    model_ = gensim.models.Word2Vec(all_doc, size=int(config['MODEL']['embed_size']),\n",
    "                                    window=int(config['MODEL']['window']),\n",
    "                                    workers=multiprocessing.cpu_count(),\n",
    "                                    sg=1, iter=int(config['MODEL']['iteration']),\n",
    "                                    negative=int(config['MODEL']['negative']),\n",
    "                                    min_count=int(config['MODEL']['min_count']), seed=int(config['MODEL']['seed']))\n",
    "else:\n",
    "    print('\\nFine-tune the pre-trained language model ...')\n",
    "    model_ = gensim.models.Word2Vec.load(config['MODEL']['pre_train_model'])\n",
    "    if len(all_doc) > 0:\n",
    "        model_.min_count = int(config['MODEL']['min_count'])\n",
    "        model_.build_vocab(all_doc, update=True)\n",
    "        model_.train(all_doc, total_examples=model_.corpus_count, epochs=int(config['MODEL']['epoch']))\n",
    "\n",
    "model_.save(config['BASIC']['embedding_dir']+\"2\")\n",
    "\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\"2.txt\", binary=False) # <-- differing name of embeddings\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\"2.bin\", binary=True)\n",
    "\n",
    "print('Time for learning the language model: %s seconds' % (time.time() - start_time))\n",
    "print('Model saved. Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-remove",
   "metadata": {},
   "source": [
    "#### config 3. \n",
    "\n",
    "Owl2vec* configuration changes:\n",
    "\n",
    "> number of iterations in training the language model: 100\n",
    "\n",
    "> window size for gensim word2vec model: 10\n",
    "\n",
    "Embedding results saved with \"3\" at the end of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accompanied-petite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: There are 302 triples in the ontology\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.08221006393432617 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.0388340950012207 seconds \n",
      "INFO: \tExtracting class membership triples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Access the ontology ...\n",
      "\n",
      "Calculate the ontology projection ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \t\tTime extracting class membership: 0.22005772590637207 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.012752294540405273 seconds \n",
      "INFO: \tExtracting triples associated to Has_base\n",
      "INFO: \t\tTime extracting triples for property: 0.17971420288085938 seconds \n",
      "INFO: \tExtracting triples associated to Has_ingredient\n",
      "INFO: \t\tTime extracting triples for property: 0.16765308380126953 seconds \n",
      "INFO: \tExtracting triples associated to Has_location\n",
      "INFO: \t\tTime extracting triples for property: 0.17580008506774902 seconds \n",
      "INFO: \tExtracting triples associated to Has_topping\n",
      "INFO: \t\tTime extracting triples for property: 0.14914321899414062 seconds \n",
      "INFO: \tExtracting triples associated to Is_base_of\n",
      "INFO: \t\tTime extracting triples for property: 0.15640711784362793 seconds \n",
      "INFO: \tExtracting triples associated to Is_ingredient_of\n",
      "INFO: \t\tTime extracting triples for property: 0.19498181343078613 seconds \n",
      "INFO: \tExtracting triples associated to Is_located_in\n",
      "INFO: \t\tTime extracting triples for property: 0.16948819160461426 seconds \n",
      "INFO: \tExtracting triples associated to Is_topping_of\n",
      "INFO: \t\tTime extracting triples for property: 0.17273807525634766 seconds \n",
      "INFO: \tExtracting triples associated to Served_at\n",
      "INFO: \t\tTime extracting triples for property: 0.2071080207824707 seconds \n",
      "INFO: \tExtracting triples associated to Serves\n",
      "INFO: \t\tTime extracting triples for property: 0.3013010025024414 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.22324371337890625 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 0.3702361583709717 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.10373306274414062 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract classes and individuals ...\n",
      "\n",
      "Extract axioms ...\n",
      "\n",
      "Extract annotations ...\n",
      "\n",
      "Generate URI document ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: collected 210 word types from a corpus of 12427 raw words and 2356 sentences\n",
      "INFO: Loading a fresh vocabulary\n",
      "INFO: effective_min_count=1 retains 210 unique words (100% of original 210, drops 0)\n",
      "INFO: effective_min_count=1 leaves 12427 word corpus (100% of original 12427, drops 0)\n",
      "INFO: deleting the raw counts dictionary of 210 items\n",
      "INFO: sample=0.001 downsamples 81 most-common words\n",
      "INFO: downsampling leaves estimated 5150 word corpus (41.4% of prior 12427)\n",
      "INFO: estimated required memory for 210 words and 100 dimensions: 273000 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: training model with 4 workers on 210 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=10\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 716 walks for 50 seed entities\n",
      "Extracted 67 axiom sentences\n",
      "\n",
      "Generate literal document ...\n",
      "Extracted 7 annotation sentences\n",
      "\n",
      "Generate mixture document ...\n",
      "URI_Doc: 783, Lit_Doc: 790, Mix_Doc: 783\n",
      "Time for document construction: 3.5813281536102295 seconds\n",
      "\n",
      "Train the language model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 12427 raw words (5167 effective words) took 0.0s, 127666 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 12427 raw words (5139 effective words) took 0.1s, 100094 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 12427 raw words (5176 effective words) took 0.0s, 120311 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 12427 raw words (5179 effective words) took 0.0s, 116170 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 12427 raw words (5247 effective words) took 0.0s, 132868 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 12427 raw words (5120 effective words) took 0.0s, 115308 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 12427 raw words (5136 effective words) took 0.0s, 140827 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 12427 raw words (5148 effective words) took 0.0s, 140192 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 12427 raw words (5165 effective words) took 0.0s, 133460 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 12427 raw words (5168 effective words) took 0.0s, 114420 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 11 : training on 12427 raw words (5108 effective words) took 0.0s, 109611 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 12 : training on 12427 raw words (5141 effective words) took 0.0s, 136676 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 13 : training on 12427 raw words (5134 effective words) took 0.0s, 124707 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 14 : training on 12427 raw words (5181 effective words) took 0.0s, 137008 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 15 : training on 12427 raw words (5192 effective words) took 0.0s, 137103 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 16 : training on 12427 raw words (5148 effective words) took 0.0s, 133218 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 17 : training on 12427 raw words (5135 effective words) took 0.0s, 139150 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 18 : training on 12427 raw words (5122 effective words) took 0.0s, 158463 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 19 : training on 12427 raw words (5163 effective words) took 0.0s, 121591 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 20 : training on 12427 raw words (5122 effective words) took 0.0s, 156907 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 21 : training on 12427 raw words (5122 effective words) took 0.0s, 143025 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 22 : training on 12427 raw words (5160 effective words) took 0.0s, 137925 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 23 : training on 12427 raw words (5145 effective words) took 0.0s, 165544 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 24 : training on 12427 raw words (5069 effective words) took 0.0s, 158565 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 25 : training on 12427 raw words (5039 effective words) took 0.0s, 172594 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 26 : training on 12427 raw words (5124 effective words) took 0.0s, 163820 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 27 : training on 12427 raw words (5181 effective words) took 0.0s, 142803 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 28 : training on 12427 raw words (5186 effective words) took 0.0s, 157904 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 29 : training on 12427 raw words (5202 effective words) took 0.0s, 136165 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: EPOCH - 30 : training on 12427 raw words (5172 effective words) took 0.0s, 158949 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 31 : training on 12427 raw words (5133 effective words) took 0.0s, 141737 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 32 : training on 12427 raw words (5181 effective words) took 0.0s, 149359 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 33 : training on 12427 raw words (5185 effective words) took 0.0s, 149430 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 34 : training on 12427 raw words (5156 effective words) took 0.0s, 134957 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 35 : training on 12427 raw words (5192 effective words) took 0.0s, 135858 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 36 : training on 12427 raw words (5181 effective words) took 0.0s, 140074 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 37 : training on 12427 raw words (5173 effective words) took 0.1s, 73093 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 38 : training on 12427 raw words (5117 effective words) took 0.0s, 151849 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 39 : training on 12427 raw words (5096 effective words) took 0.0s, 148890 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 40 : training on 12427 raw words (5229 effective words) took 0.0s, 149266 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 41 : training on 12427 raw words (5113 effective words) took 0.0s, 158047 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 42 : training on 12427 raw words (5194 effective words) took 0.0s, 145711 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 43 : training on 12427 raw words (5174 effective words) took 0.0s, 154914 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 44 : training on 12427 raw words (5174 effective words) took 0.0s, 143863 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 45 : training on 12427 raw words (5227 effective words) took 0.0s, 136972 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 46 : training on 12427 raw words (5103 effective words) took 0.0s, 138653 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 47 : training on 12427 raw words (5137 effective words) took 0.0s, 136533 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 48 : training on 12427 raw words (5099 effective words) took 0.0s, 148635 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 49 : training on 12427 raw words (5195 effective words) took 0.0s, 137716 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 50 : training on 12427 raw words (5155 effective words) took 0.0s, 141499 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 51 : training on 12427 raw words (5184 effective words) took 0.0s, 134961 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 52 : training on 12427 raw words (5177 effective words) took 0.0s, 133001 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 53 : training on 12427 raw words (5153 effective words) took 0.0s, 130516 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 54 : training on 12427 raw words (5085 effective words) took 0.0s, 188688 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 55 : training on 12427 raw words (5178 effective words) took 0.0s, 139828 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 56 : training on 12427 raw words (5086 effective words) took 0.0s, 156145 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 57 : training on 12427 raw words (5208 effective words) took 0.0s, 148828 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 58 : training on 12427 raw words (5214 effective words) took 0.0s, 173186 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 59 : training on 12427 raw words (5109 effective words) took 0.0s, 158386 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 60 : training on 12427 raw words (5115 effective words) took 0.0s, 128867 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 61 : training on 12427 raw words (5224 effective words) took 0.0s, 153793 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 62 : training on 12427 raw words (5129 effective words) took 0.0s, 149834 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 63 : training on 12427 raw words (5169 effective words) took 0.0s, 129614 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 64 : training on 12427 raw words (5152 effective words) took 0.0s, 157279 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 65 : training on 12427 raw words (5115 effective words) took 0.0s, 143804 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 66 : training on 12427 raw words (5224 effective words) took 0.0s, 164010 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 67 : training on 12427 raw words (5121 effective words) took 0.0s, 145937 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 68 : training on 12427 raw words (5237 effective words) took 0.0s, 164071 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 69 : training on 12427 raw words (5178 effective words) took 0.0s, 132868 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 70 : training on 12427 raw words (5076 effective words) took 0.0s, 160521 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 71 : training on 12427 raw words (5123 effective words) took 0.0s, 128055 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 72 : training on 12427 raw words (5092 effective words) took 0.0s, 151830 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 73 : training on 12427 raw words (5181 effective words) took 0.0s, 168092 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 74 : training on 12427 raw words (5104 effective words) took 0.0s, 134290 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 75 : training on 12427 raw words (5134 effective words) took 0.0s, 135589 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 76 : training on 12427 raw words (5177 effective words) took 0.0s, 158156 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 77 : training on 12427 raw words (5277 effective words) took 0.0s, 132047 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 78 : training on 12427 raw words (5182 effective words) took 0.0s, 177606 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 79 : training on 12427 raw words (5178 effective words) took 0.0s, 150227 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 80 : training on 12427 raw words (5076 effective words) took 0.0s, 147903 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 81 : training on 12427 raw words (5205 effective words) took 0.0s, 160127 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 82 : training on 12427 raw words (5144 effective words) took 0.0s, 169438 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 83 : training on 12427 raw words (5097 effective words) took 0.0s, 158479 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 84 : training on 12427 raw words (5115 effective words) took 0.0s, 175343 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 85 : training on 12427 raw words (5162 effective words) took 0.0s, 134507 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 86 : training on 12427 raw words (5176 effective words) took 0.0s, 157097 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 87 : training on 12427 raw words (5163 effective words) took 0.0s, 138149 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 88 : training on 12427 raw words (5115 effective words) took 0.0s, 145007 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 89 : training on 12427 raw words (5197 effective words) took 0.0s, 147975 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 90 : training on 12427 raw words (5181 effective words) took 0.0s, 145970 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 91 : training on 12427 raw words (5161 effective words) took 0.0s, 152989 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 92 : training on 12427 raw words (5193 effective words) took 0.0s, 145630 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 93 : training on 12427 raw words (5192 effective words) took 0.0s, 154558 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 94 : training on 12427 raw words (5119 effective words) took 0.0s, 176808 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 95 : training on 12427 raw words (5156 effective words) took 0.0s, 168333 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 96 : training on 12427 raw words (5119 effective words) took 0.0s, 181572 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 97 : training on 12427 raw words (5193 effective words) took 0.0s, 147166 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 98 : training on 12427 raw words (5139 effective words) took 0.0s, 153374 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 99 : training on 12427 raw words (5110 effective words) took 0.0s, 179163 effective words/s\n",
      "DEBUG: job loop exiting, total 2 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "DEBUG: worker exiting, processed 0 jobs\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG: worker exiting, processed 1 jobs\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 100 : training on 12427 raw words (5097 effective words) took 0.0s, 152375 effective words/s\n",
      "INFO: training on a 1242700 raw words (515397 effective words) took 4.6s, 113262 effective words/s\n",
      "INFO: saving Word2Vec object under ./output_embedding/created_ontology.embeddings3, separately None\n",
      "INFO: not storing attribute vectors_norm\n",
      "INFO: not storing attribute cum_table\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings3', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: saved ./output_embedding/created_ontology.embeddings3\n",
      "INFO: storing 210x100 projection weights into ./output_embedding/created_ontology.embeddings3.txt\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings3.txt', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "INFO: storing 210x100 projection weights into ./output_embedding/created_ontology.embeddings3.bin\n",
      "DEBUG: {'uri': './output_embedding/created_ontology.embeddings3.bin', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for learning the language model: 4.703548192977905 seconds\n",
      "Model saved. Done!\n"
     ]
    }
   ],
   "source": [
    "# using lab 9 code, below code being straight from OWl2Vec_Standalone.py\n",
    "# running on ontology_with_data\n",
    "# embedding_dir = ./output_embedding2/created_ontology.embeddings\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import configparser\n",
    "\n",
    "sys.path.append('./rdf2vec/')\n",
    "sys.path.append('./lib/')\n",
    "from RDF2Vec_Embed import get_rdf2vec_walks\n",
    "from Label import pre_process_words, URI_parse\n",
    "from Onto_Projection import Reasoner, OntologyProjection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--ontology_file\", type=str, default=None, help=\"The input ontology for embedding\")\n",
    "parser.add_argument(\"--embedding_dir\", type=str, default=None, help=\"The output embedding directory\")\n",
    "parser.add_argument(\"--config_file\", type=str, default='default.cfg', help=\"Configuration file\")\n",
    "parser.add_argument(\"--URI_Doc\", help=\"Using URI document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Lit_Doc\", help=\"Using literal document\", action=\"store_true\")\n",
    "parser.add_argument(\"--Mix_Doc\", help=\"Using mixture document\", action=\"store_true\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# read and combine configurations\n",
    "# overwrite the parameters in the configuration file by the command parameters\n",
    "config = configparser.ConfigParser()\n",
    "config.read(FLAGS.config_file)\n",
    "if FLAGS.ontology_file is not None:\n",
    "    config['BASIC']['ontology_file'] = FLAGS.ontology_file\n",
    "if FLAGS.embedding_dir is not None:\n",
    "    config['BASIC']['embedding_dir'] = FLAGS.embedding_dir\n",
    "if FLAGS.URI_Doc:\n",
    "    config['DOCUMENT']['URI_Doc'] = 'yes'\n",
    "if FLAGS.Lit_Doc:\n",
    "    config['DOCUMENT']['Lit_Doc'] = 'yes'\n",
    "if FLAGS.Mix_Doc:\n",
    "    config['DOCUMENT']['Mix_Doc'] = 'yes'\n",
    "if 'cache_dir' not in config['DOCUMENT']:\n",
    "    config['DOCUMENT']['cache_dir'] = './cache'\n",
    "if 'embedding_dir' not in config['BASIC']:\n",
    "    config['BASIC']['embedding_dir'] = os.path.join(config['DOCUMENT']['cache_dir'], 'output')\n",
    "\n",
    "start_time = time.time()\n",
    "if ('ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes') or \\\n",
    "        'pre_entity_file' not in config['DOCUMENT'] or 'pre_axiom_file' not in config['DOCUMENT'] or \\\n",
    "        'pre_annotation_file' not in config['DOCUMENT']:\n",
    "    print('\\n Access the ontology ...')\n",
    "    projection = OntologyProjection(config['BASIC']['ontology_file'], reasoner=Reasoner.STRUCTURAL, only_taxonomy=False,\n",
    "                                    bidirectional_taxonomy=True, include_literals=True, avoid_properties=set(),\n",
    "                                    additional_preferred_labels_annotations=set(),\n",
    "                                    additional_synonyms_annotations=set(),\n",
    "                                    memory_reasoner='13351')\n",
    "else:\n",
    "    projection = None\n",
    "\n",
    "# Ontology projection\n",
    "if 'ontology_projection' in config['DOCUMENT'] and config['DOCUMENT']['ontology_projection'] == 'yes':\n",
    "    print('\\nCalculate the ontology projection ...')\n",
    "    projection.extractProjection()\n",
    "    onto_projection_file = os.path.join(config['DOCUMENT']['cache_dir'], 'projection.ttl')\n",
    "    projection.saveProjectionGraph(onto_projection_file)\n",
    "    ontology_file = onto_projection_file\n",
    "else:\n",
    "    ontology_file = config['BASIC']['ontology_file']\n",
    "\n",
    "# Extract and save seed entities (classes and individuals)\n",
    "# Or read entities specified by the user\n",
    "if 'pre_entity_file' in config['DOCUMENT']:\n",
    "    entities = [line.strip() for line in open(config['DOCUMENT']['pre_entity_file']).readlines()]\n",
    "else:\n",
    "    print('\\nExtract classes and individuals ...')\n",
    "    projection.extractEntityURIs()\n",
    "    classes = projection.getClassURIs()\n",
    "    individuals = projection.getIndividualURIs()\n",
    "    entities = classes.union(individuals)\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'entities.txt'), 'w') as f:\n",
    "        for e in entities:\n",
    "            f.write('%s\\n' % e)\n",
    "\n",
    "# Extract axioms in Manchester Syntax if it is not pre_axiom_file is not set\n",
    "if 'pre_axiom_file' not in config['DOCUMENT']:\n",
    "    print('\\nExtract axioms ...')\n",
    "    projection.createManchesterSyntaxAxioms()\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt'), 'w') as f:\n",
    "        for ax in projection.axioms_manchester:\n",
    "            f.write('%s\\n' % ax)\n",
    "\n",
    "# If pre_annotation_file is set, directly read annotations\n",
    "# else, read annotations including rdfs:label and other literals from the ontology\n",
    "#   Extract annotations: 1) English label of each entity, by rdfs:label or skos:preferredLabel\n",
    "#                        2) None label annotations as sentences of the literal document\n",
    "uri_label, annotations = dict(), list()\n",
    "\n",
    "if 'pre_annotation_file' in config['DOCUMENT']:\n",
    "    with open(config['DOCUMENT']['pre_annotation_file']) as f:\n",
    "        for line in f.readlines():\n",
    "            tmp = line.strip().split()\n",
    "            if tmp[1] == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "                uri_label[tmp[0]] = pre_process_words(tmp[2:])\n",
    "            else:\n",
    "                annotations.append([tmp[0]] + tmp[2:])\n",
    "\n",
    "else:\n",
    "    print('\\nExtract annotations ...')\n",
    "    projection.indexAnnotations()\n",
    "    for e in entities:\n",
    "        if e in projection.entityToPreferredLabels and len(projection.entityToPreferredLabels[e]) > 0:\n",
    "            label = list(projection.entityToPreferredLabels[e])[0]\n",
    "            uri_label[e] = pre_process_words(words=label.split())\n",
    "    for e in entities:\n",
    "        if e in projection.entityToAllLexicalLabels:\n",
    "            for v in projection.entityToAllLexicalLabels[e]:\n",
    "                if (v is not None) and \\\n",
    "                        (not (e in projection.entityToPreferredLabels and v in projection.entityToPreferredLabels[e])):\n",
    "                    annotation = [e] + v.split()\n",
    "                    annotations.append(annotation)\n",
    "\n",
    "    with open(os.path.join(config['DOCUMENT']['cache_dir'], 'annotations.txt'), 'w') as f:\n",
    "        for e in projection.entityToPreferredLabels:\n",
    "            for v in projection.entityToPreferredLabels[e]:\n",
    "                f.write('%s preferred_label %s\\n' % (e, v))\n",
    "        for a in annotations:\n",
    "            f.write('%s\\n' % ' '.join(a))\n",
    "\n",
    "\n",
    "# read URI document\n",
    "# two parts: walks, axioms (if the axiom file exists)\n",
    "walk_sentences, axiom_sentences, URI_Doc = list(), list(), list()\n",
    "if 'URI_Doc' in config['DOCUMENT'] and config['DOCUMENT']['URI_Doc'] == 'yes':\n",
    "    print('\\nGenerate URI document ...')\n",
    "    #walker_type=config['DOCUMENT']['walker']\n",
    "    walks_ = get_rdf2vec_walks(onto_file=ontology_file, walker_type=config['DOCUMENT']['walker'],\n",
    "                               walk_depth=int(config['DOCUMENT']['walk_depth']), classes=entities)\n",
    "    print('Extracted %d walks for %d seed entities' % (len(walks_), len(entities)))\n",
    "    walk_sentences += [list(map(str, x)) for x in walks_]\n",
    "\n",
    "    axiom_file = os.path.join(config['DOCUMENT']['cache_dir'], 'axioms.txt')\n",
    "    if os.path.exists(axiom_file):\n",
    "        for line in open(axiom_file).readlines():\n",
    "            axiom_sentence = [item for item in line.strip().split()]\n",
    "            axiom_sentences.append(axiom_sentence)\n",
    "    print('Extracted %d axiom sentences' % len(axiom_sentences))\n",
    "    URI_Doc = walk_sentences + axiom_sentences\n",
    "\n",
    "\n",
    "# Some entities have English labels\n",
    "# Keep the name of built-in properties (those starting with http://www.w3.org)\n",
    "# Some entities have no labels, then use the words in their URI name\n",
    "def label_item(item):\n",
    "    if item in uri_label:\n",
    "        return uri_label[item]\n",
    "    elif item.startswith('http://www.w3.org'):\n",
    "        return [item.split('#')[1].lower()]\n",
    "    elif item.startswith('http://'):\n",
    "        return URI_parse(uri=item)\n",
    "    else:\n",
    "        return [item.lower()]\n",
    "\n",
    "\n",
    "# read literal document\n",
    "# two parts: literals in the annotations (subject's label + literal words)\n",
    "#            replacing walk/axiom sentences by words in their labels\n",
    "Lit_Doc = list()\n",
    "if 'Lit_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Lit_Doc'] == 'yes':\n",
    "    print('\\nGenerate literal document ...')\n",
    "    for annotation in annotations:\n",
    "        processed_words = pre_process_words(annotation[1:])\n",
    "        if len(processed_words) > 0:\n",
    "            Lit_Doc.append(label_item(item=annotation[0]) + processed_words)\n",
    "    print('Extracted %d annotation sentences' % len(Lit_Doc))\n",
    "\n",
    "    for sentence in walk_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "    for sentence in axiom_sentences:\n",
    "        lit_sentence = list()\n",
    "        for item in sentence:\n",
    "            lit_sentence += label_item(item=item)\n",
    "        Lit_Doc.append(lit_sentence)\n",
    "\n",
    "# read mixture document\n",
    "# for each axiom/walk sentence, all): for each entity, keep its entity URI, replace the others by label words\n",
    "#                            random): randomly select one entity, keep its entity URI, replace the others by label words\n",
    "Mix_Doc = list()\n",
    "if 'Mix_Doc' in config['DOCUMENT'] and config['DOCUMENT']['Mix_Doc'] == 'yes':\n",
    "    print('\\nGenerate mixture document ...')\n",
    "    for sentence in walk_sentences + axiom_sentences:\n",
    "        if config['DOCUMENT']['Mix_Type'] == 'all':\n",
    "            for index in range(len(sentence)):\n",
    "                mix_sentence = list()\n",
    "                for i, item in enumerate(sentence):\n",
    "                    mix_sentence += [item] if i == index else label_item(item=item)\n",
    "                Mix_Doc.append(mix_sentence)\n",
    "        elif config['DOCUMENT']['Mix_Type'] == 'random':\n",
    "            random_index = random.randint(0, len(sentence) - 1)\n",
    "            mix_sentence = list()\n",
    "            for i, item in enumerate(sentence):\n",
    "                mix_sentence += [item] if i == random_index else label_item(item=item)\n",
    "            Mix_Doc.append(mix_sentence)\n",
    "\n",
    "print('URI_Doc: %d, Lit_Doc: %d, Mix_Doc: %d' % (len(URI_Doc), len(Lit_Doc), len(Mix_Doc)))\n",
    "all_doc = URI_Doc + Lit_Doc + Mix_Doc\n",
    "\n",
    "\n",
    "print('Time for document construction: %s seconds' % (time.time() - start_time))\n",
    "random.shuffle(all_doc)\n",
    "\n",
    "\n",
    "#Save all_doc\n",
    "with open(os.path.join(config['DOCUMENT']['cache_dir'], 'document_sentences.txt'), 'w') as f:\n",
    "    for sentence in all_doc:\n",
    "        for w in sentence:\n",
    "            f.write('%s ' % w)\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# learn the language model (train a new model or fine tune the pre-trained model)\n",
    "start_time = time.time()\n",
    "if 'pre_train_model' not in config['MODEL'] or not os.path.exists(config['MODEL']['pre_train_model']):\n",
    "    print('\\nTrain the language model ...')\n",
    "    model_ = gensim.models.Word2Vec(all_doc, size=int(config['MODEL']['embed_size']),\n",
    "                                    window=int(config['MODEL']['window']),\n",
    "                                    workers=multiprocessing.cpu_count(),\n",
    "                                    sg=1, iter=int(config['MODEL']['iteration']),\n",
    "                                    negative=int(config['MODEL']['negative']),\n",
    "                                    min_count=int(config['MODEL']['min_count']), seed=int(config['MODEL']['seed']))\n",
    "else:\n",
    "    print('\\nFine-tune the pre-trained language model ...')\n",
    "    model_ = gensim.models.Word2Vec.load(config['MODEL']['pre_train_model'])\n",
    "    if len(all_doc) > 0:\n",
    "        model_.min_count = int(config['MODEL']['min_count'])\n",
    "        model_.build_vocab(all_doc, update=True)\n",
    "        model_.train(all_doc, total_examples=model_.corpus_count, epochs=int(config['MODEL']['epoch']))\n",
    "\n",
    "model_.save(config['BASIC']['embedding_dir']+\"3\")\n",
    "\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\"3.txt\", binary=False) # <-- differing name of embeddings\n",
    "model_.wv.save_word2vec_format(config['BASIC']['embedding_dir']+\"3.bin\", binary=True)\n",
    "\n",
    "print('Time for learning the language model: %s seconds' % (time.time() - start_time))\n",
    "print('Model saved. Done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-shield",
   "metadata": {},
   "source": [
    "The embeddings for each of the 3 differnt configurations have been saved in the output_embedding file. In said file, a notebook can be found which will perform the rest of the ontology embedding task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
