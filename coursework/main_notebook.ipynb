{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "optimum-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "from rdflib import Graph, URIRef, BNode, Literal, Namespace, plugins\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "from rdflib.serializer import Serializer\n",
    "import rdflib\n",
    "import owlrl\n",
    "from lookup import DBpediaLookup\n",
    "from stringcmp import isub\n",
    "from owlready2 import get_ontology\n",
    "import Levenshtein as Lev\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-spain",
   "metadata": {},
   "source": [
    "## Initial Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "nominated-behavior",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>currency</th>\n",
       "      <th>item description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>J &amp; G Restaurant</td>\n",
       "      <td>35 S Main St</td>\n",
       "      <td>East Granby</td>\n",
       "      <td>US</td>\n",
       "      <td>6026</td>\n",
       "      <td>CT</td>\n",
       "      <td>American Restaurant,Italian Restaurant,America...</td>\n",
       "      <td>White Pizza (medium)</td>\n",
       "      <td>12.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>Ricotta and parmesan cheese, garlic and herbs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>Valentino Pizza I</td>\n",
       "      <td>5536 Torresdale Ave</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>US</td>\n",
       "      <td>19124</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Pizza Skins</td>\n",
       "      <td>3.95</td>\n",
       "      <td>USD</td>\n",
       "      <td>With sour cream, sauce and mozzarella cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>Bella Piazza</td>\n",
       "      <td>286 Us Highway 46</td>\n",
       "      <td>Fairfield</td>\n",
       "      <td>US</td>\n",
       "      <td>7004</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Italian Restaurant</td>\n",
       "      <td>Gnocchi Bella Pizza</td>\n",
       "      <td>8.99</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>D. Vino Italian Food and Wine Bar - Monte Carlo</td>\n",
       "      <td>3770 Las Vegas Blvd S</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>US</td>\n",
       "      <td>89109</td>\n",
       "      <td>NV</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>Caprese Pizza</td>\n",
       "      <td>14.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>Fresh Mozzarella, Slices of Fresh Roma Tomatoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Giovanni's Pizzeria</td>\n",
       "      <td>250 Sicklerville Rd</td>\n",
       "      <td>Sicklerville</td>\n",
       "      <td>US</td>\n",
       "      <td>8081</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Restaurants,Pizza Place,Pizza</td>\n",
       "      <td>Stuffed Cheese Pizza</td>\n",
       "      <td>13.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Giovanni's Pizzeria</td>\n",
       "      <td>250 Sicklerville Rd</td>\n",
       "      <td>Sicklerville</td>\n",
       "      <td>US</td>\n",
       "      <td>8081</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Restaurants,Pizza Place,Pizza</td>\n",
       "      <td>1 Ingredient Pizza</td>\n",
       "      <td>17.20</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Pasta Loft</td>\n",
       "      <td>241 Union Sq</td>\n",
       "      <td>Milford</td>\n",
       "      <td>US</td>\n",
       "      <td>3055</td>\n",
       "      <td>NH</td>\n",
       "      <td>Italian Restaurant,Restaurant</td>\n",
       "      <td>White Pizza</td>\n",
       "      <td>11.99</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Woolworth Tower Kitchen</td>\n",
       "      <td>233 Broadway</td>\n",
       "      <td>New York</td>\n",
       "      <td>US</td>\n",
       "      <td>10279</td>\n",
       "      <td>Nyc</td>\n",
       "      <td>Restaurant,New York City</td>\n",
       "      <td>Grilled Pizza</td>\n",
       "      <td>10.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>Casey's General Store</td>\n",
       "      <td>400 W Mondamin St</td>\n",
       "      <td>Minooka</td>\n",
       "      <td>US</td>\n",
       "      <td>60447</td>\n",
       "      <td>IL</td>\n",
       "      <td>Restaurants,Food &amp; Entertainment,Gas Station</td>\n",
       "      <td>Breakfast Pizza Slice</td>\n",
       "      <td>1.99</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>Jerry's Pizza &amp; Subs</td>\n",
       "      <td>924 W 436</td>\n",
       "      <td>Altamonte Springs</td>\n",
       "      <td>US</td>\n",
       "      <td>32714</td>\n",
       "      <td>FL</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Pizza By The Slice</td>\n",
       "      <td>2.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name                address  \\\n",
       "1616                                 J & G Restaurant           35 S Main St   \n",
       "1909                                Valentino Pizza I    5536 Torresdale Ave   \n",
       "3051                                     Bella Piazza      286 Us Highway 46   \n",
       "315   D. Vino Italian Food and Wine Bar - Monte Carlo  3770 Las Vegas Blvd S   \n",
       "1541                              Giovanni's Pizzeria    250 Sicklerville Rd   \n",
       "1536                              Giovanni's Pizzeria    250 Sicklerville Rd   \n",
       "2075                                       Pasta Loft           241 Union Sq   \n",
       "497                           Woolworth Tower Kitchen           233 Broadway   \n",
       "3105                            Casey's General Store      400 W Mondamin St   \n",
       "1256                             Jerry's Pizza & Subs              924 W 436   \n",
       "\n",
       "                   city country postcode state  \\\n",
       "1616        East Granby      US     6026    CT   \n",
       "1909       Philadelphia      US    19124    PA   \n",
       "3051          Fairfield      US     7004    NJ   \n",
       "315           Las Vegas      US    89109    NV   \n",
       "1541       Sicklerville      US     8081    NJ   \n",
       "1536       Sicklerville      US     8081    NJ   \n",
       "2075            Milford      US     3055    NH   \n",
       "497            New York      US    10279   Nyc   \n",
       "3105            Minooka      US    60447    IL   \n",
       "1256  Altamonte Springs      US    32714    FL   \n",
       "\n",
       "                                             categories  \\\n",
       "1616  American Restaurant,Italian Restaurant,America...   \n",
       "1909                                        Pizza Place   \n",
       "3051                                 Italian Restaurant   \n",
       "315                                          Restaurant   \n",
       "1541                      Restaurants,Pizza Place,Pizza   \n",
       "1536                      Restaurants,Pizza Place,Pizza   \n",
       "2075                      Italian Restaurant,Restaurant   \n",
       "497                            Restaurant,New York City   \n",
       "3105       Restaurants,Food & Entertainment,Gas Station   \n",
       "1256                                        Pizza Place   \n",
       "\n",
       "                  menu item  item value currency  \\\n",
       "1616   White Pizza (medium)       12.50      USD   \n",
       "1909            Pizza Skins        3.95      USD   \n",
       "3051    Gnocchi Bella Pizza        8.99      USD   \n",
       "315           Caprese Pizza       14.00      USD   \n",
       "1541   Stuffed Cheese Pizza       13.50      USD   \n",
       "1536     1 Ingredient Pizza       17.20      USD   \n",
       "2075            White Pizza       11.99      USD   \n",
       "497           Grilled Pizza       10.00      USD   \n",
       "3105  Breakfast Pizza Slice        1.99      USD   \n",
       "1256     Pizza By The Slice        2.00      USD   \n",
       "\n",
       "                                       item description  \n",
       "1616     Ricotta and parmesan cheese, garlic and herbs.  \n",
       "1909       With sour cream, sauce and mozzarella cheese  \n",
       "3051                                                NaN  \n",
       "315   Fresh Mozzarella, Slices of Fresh Roma Tomatoe...  \n",
       "1541                                                NaN  \n",
       "1536                                                NaN  \n",
       "2075                                                NaN  \n",
       "497                                                 NaN  \n",
       "3105                                                NaN  \n",
       "1256                                                NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/Jake/Documents/uni/Semantic Web Technologies/coursework/INM713_coursework_data_pizza_8358_1_reduced.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "existing-penetration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>currency</th>\n",
       "      <th>item description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701</td>\n",
       "      <td>OR</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Bianca Pizza</td>\n",
       "      <td>22.50</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Little Pizza Paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>Bend</td>\n",
       "      <td>US</td>\n",
       "      <td>97701</td>\n",
       "      <td>OR</td>\n",
       "      <td>Pizza Place</td>\n",
       "      <td>Cheese Pizza</td>\n",
       "      <td>18.95</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Margherita</td>\n",
       "      <td>12.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Mushroom</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>US</td>\n",
       "      <td>90049</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>American Restaurant,Bar,Bakery</td>\n",
       "      <td>Pizza, Puttenesca</td>\n",
       "      <td>13.00</td>\n",
       "      <td>USD</td>\n",
       "      <td>Olives, onions, capers, tomatoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                  address  \\\n",
       "0  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "1  Little Pizza Paradise  Cascade Village Mall Across From Target   \n",
       "2          The Brentwood                     148 S Barrington Ave   \n",
       "3          The Brentwood                     148 S Barrington Ave   \n",
       "4          The Brentwood                     148 S Barrington Ave   \n",
       "\n",
       "          city country postcode      state                      categories  \\\n",
       "0         Bend      US    97701         OR                     Pizza Place   \n",
       "1         Bend      US    97701         OR                     Pizza Place   \n",
       "2  Los Angeles      US    90049  Brentwood  American Restaurant,Bar,Bakery   \n",
       "3  Los Angeles      US    90049  Brentwood  American Restaurant,Bar,Bakery   \n",
       "4  Los Angeles      US    90049  Brentwood  American Restaurant,Bar,Bakery   \n",
       "\n",
       "           menu item  item value currency                  item description  \n",
       "0       Bianca Pizza       22.50      USD                               NaN  \n",
       "1       Cheese Pizza       18.95      USD                               NaN  \n",
       "2  Pizza, Margherita       12.00      USD                               NaN  \n",
       "3    Pizza, Mushroom       13.00      USD                               NaN  \n",
       "4  Pizza, Puttenesca       13.00      USD  Olives, onions, capers, tomatoes  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-mapping",
   "metadata": {},
   "source": [
    "It can be seen that there a multiple different pizzas/items for one specific establishment, and so it may be necessary to combine the item name and the establishment name in to one variable to load in to the ontology, in order for easy reading and distinction, as well as not getting lots of duplicate named pizzas in each part of the pizza part of the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "improving-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US']\n"
     ]
    }
   ],
   "source": [
    "print(df['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-quebec",
   "metadata": {},
   "source": [
    "All restaurants in this data set are in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pursuant-distance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3510, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-pension",
   "metadata": {},
   "source": [
    "There are 3510 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "relevant-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the unnecessary currency column\n",
    "\n",
    "df.drop('currency', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "elementary-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                   0\n",
       "address                0\n",
       "city                   0\n",
       "country                0\n",
       "postcode              65\n",
       "state                  0\n",
       "categories             0\n",
       "menu item              0\n",
       "item value           562\n",
       "item description    1984\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-swing",
   "metadata": {},
   "source": [
    "There are 1984 observations which have missing item descriptions, something that may need addressing to retrieve suitable information about them. Postcodes and prices are also missing, but these cannot be deduced from other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-municipality",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-precipitation",
   "metadata": {},
   "source": [
    "Before features can be engineered, which will likely involve some simple text processing, it is necessary to strip the data of punctuation and capitalisation of words, as well as any non_ascii characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "thousand-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of non-ascii characters. solution found at:\n",
    "# https://stackoverflow.com/questions/36340627/remove-non-ascii-characters-from-pandas-column\n",
    "\n",
    "df['name'] = df['name'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "df['city'] = df['city'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "df['country'] = df['country'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "df['state'] = df['state'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "df['categories'] = df['categories'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "df['menu item'] = df['menu item'].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "\n",
    "\n",
    "# punctuation translator solution found from:\n",
    "# https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate/34294022\n",
    "\n",
    "# removing punctuation and upper case letters from all necessary string variables to make suitable for\n",
    "# URI formatting formatting later.\n",
    "\n",
    "# intializing translator\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# applying to cols (cols with NaN values will have to be dealt with differently)\n",
    "df['name'] = [string.translate(translator).lower().replace('-', '_').replace(' ', '_') for string in df['name']]\n",
    "df['city'] = [string.translate(translator).lower().replace('-', '_').replace(' ', '_') for string in df['city']]\n",
    "df['country'] = [string.translate(translator).lower().replace('-', '_').replace(' ', '_') for string in df['country']]\n",
    "df['state'] = [string.translate(translator).lower().replace('-', '_').replace(' ', '_') for string in df['state']]\n",
    "df['categories'] = [string.translate(translator).lower().replace(',', '_').replace('-', '_').replace(' ', '_') for string in df['categories']]\n",
    "df['menu item'] = [string.translate(translator).lower().replace('-', '_').replace(' ', '_') for string in df['menu item']]\n",
    "\n",
    "# replacing 'us' with 'USA':\n",
    "df['country'] = df['country'].apply(lambda x: x.replace('us', 'USA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "necessary-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the same changes to the string columns that contain NaN values\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row['postcode'] == row['postcode']:\n",
    "        df.iloc[idx, 4] = row['postcode'].translate(translator).lower().replace('-', '').replace(' ', '')\n",
    "    if row['item description'] == row['item description']:\n",
    "        df.iloc[idx, 9] = row['item description'].translate(translator).lower().replace('-', '').replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "loving-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the name of establishment and item name in new col\n",
    "\n",
    "df['item_name'] = df['menu item']+'_at_'+df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "governing-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary with all 50 states with their respective abbreviations, in order to be able to link state column\n",
    "# more successfully to Dbpedia:\n",
    "\n",
    "states = {'al': 'Alabama', 'ak': 'Alaska', 'as': 'Arkansas', 'az': 'Arizona', 'ca': 'California', 'co': 'Colorado',\n",
    "         'ct': 'Connecticut', 'de': 'Delaware', 'fl': 'Florida', 'ga': 'Georgia', 'hi': 'Hawaii', 'id': 'Idaho', \n",
    "         'il': 'Illinois', 'in': 'Indiana', 'ia': 'Iowa', 'ks': 'Kansas', 'ky': 'Kentucky', 'la': 'Louisianna', \n",
    "         'ma': 'Maryland', 'mi': 'Michigan', 'mn': 'Minnesota', 'mo': 'Missouri', 'ms': 'Mississipi', 'mt': 'Montana',\n",
    "         'nv': 'Nevada', 'ne': 'Nebraska', 'nh': 'New_Hampshire', 'nj': 'New_Jersey', 'nm': 'New_Mexico', \n",
    "         'ny': 'New_York', 'nc': 'North_Carolina', 'nd': 'North_Dakota', 'oh': 'Ohio', 'ok': 'Oklahoma', 'or': 'Oregon',\n",
    "         'pa': 'Pennsylvania', 'ri': 'Rhode_Island', 'sc': 'South_Carolina', 'sd': 'South_Dakota', 'tx': 'Texas',\n",
    "         'tn': 'Tennessee', 'ut': 'Utah', 'vt': 'Vermont', 'va': 'Virginia', 'wy': 'Wyoming', 'wi': 'Wisconsin',\n",
    "         'wa': 'Washington', 'wv': 'West_Virginia'}\n",
    "\n",
    "# iterating over the df to change the states that have abbreviations to full state names:\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row['state'] in states.keys():\n",
    "        full_state = states[row['state']]\n",
    "        df.iloc[idx, 5] = full_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ordinary-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitializing new columns to one-hot encode different types of pizzas.\n",
    "\n",
    "df[['Vegetarian_pizza', 'Meat_pizza', 'Seafood_pizza', 'Bianca', 'Hawaiian', 'Americana', 'Margherita', 'Dessert_pizza',\n",
    "   'Thin_crust', 'Deep_dish']] = 0, 0, 0, 0, 0, 0, 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-clothing",
   "metadata": {},
   "source": [
    "## One-hot encoding of different classes/data properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "extended-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising lit of buzzwords to search for for each category\n",
    "\n",
    "bianca_search = ['bianca', 'white pizza', 'tomato free']\n",
    "vegetarian_search = ['vegetarian', 'veggie', 'meat_free', 'meatfree', 'no_meat', 'vegetable', 'margherita', 'four_cheese',\n",
    "                    'bufalina', 'cheese_pizza', 'pizza_mushroom', 'mushroom_pizza', 'pizza_putanesca',]\n",
    "americana_search = ['american_pizza', 'americana', 'pepperoni_pizza', 'pizza_americana']\n",
    "margherita_search = ['margherita']\n",
    "hawaiian_search = ['hawaiian', 'pineapple']\n",
    "meat_search = ['meat', 'chicken', 'beef', 'pork', 'lamb', 'pepperoni', 'pastrami', 'salami', 'sausage', 'bacon',\n",
    "              'steak', 'chorizo', 'prosciutto', 'pancetta', 'sarda', 'diavola', 'capricciosa', 'mare_e_monti', 'ham']\n",
    "seafood_search = ['tuna', 'prawn', 'shrimp', 'oyster', 'salmon', 'anchov', 'sardine', 'clams', 'cuttlefish',\n",
    "                 'seafood', 'scallop', 'mussel', 'frutti_di_mare', 'crab']\n",
    "thin_crust_search = ['thin_crust', 'thin_base', 'crispy_base', 'crispy_crust']\n",
    "deep_dish_search = ['deep_dish', 'chicago_']\n",
    "dessert_search = ['dessert', 'chocolate', 'nutella', 'marshmallow']\n",
    "\n",
    "# applying one-hot encoding of different kinds of pizza through buzzword search\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    for each in bianca_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 14] = 1\n",
    "    \n",
    "    for each in vegetarian_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 11] = 1\n",
    "            \n",
    "    for each in americana_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 16] = 1\n",
    "            \n",
    "    for each in margherita_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 17] = 1\n",
    "            \n",
    "    for each in hawaiian_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 15] = 1\n",
    "            \n",
    "    for each in meat_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 12] = 1\n",
    "            \n",
    "    for each in seafood_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 13] = 1\n",
    "            \n",
    "    for each in thin_crust_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 19] = 1\n",
    "            \n",
    "    for each in vegetarian_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 20] = 1\n",
    "            \n",
    "    for each in dessert_search:\n",
    "        if each in row['menu item'] or each in str(row['item description']):\n",
    "            df.iloc[idx, 18] = 1\n",
    "\n",
    "            \n",
    "# re-iterating to ensure no disjoint properties have been created e.g. meat & seafood pizza with vegetarian pizza\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if ((row['Vegetarian_pizza'] == 1) &\n",
    "        (row['Meat_pizza'] == 1)):\n",
    "        \n",
    "        df.iloc[idx, 11] = 0\n",
    "    \n",
    "    if ((row['Vegetarian_pizza'] ==1) &\n",
    "        (row['Seafood_pizza'] ==1)):\n",
    "        \n",
    "        df.iloc[idx, 11] = 0\n",
    "        \n",
    "    if ((row['Vegetarian_pizza'] ==1) &\n",
    "        (row['Hawaiian'] ==1)):\n",
    "        \n",
    "        df.iloc[idx, 11] = 0\n",
    "        \n",
    "    if ((row['Meat_pizza'] ==1) &\n",
    "        (row['Margherita'] ==1)):\n",
    "        \n",
    "        df.iloc[idx, 17] = 0\n",
    "        \n",
    "    if ((row['Seafood_pizza'] ==1) &\n",
    "        (row['Margherita'] ==1)):\n",
    "        \n",
    "        df.iloc[idx, 17] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "taken-magnitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>menu item</th>\n",
       "      <th>item value</th>\n",
       "      <th>item description</th>\n",
       "      <th>...</th>\n",
       "      <th>Vegetarian_pizza</th>\n",
       "      <th>Meat_pizza</th>\n",
       "      <th>Seafood_pizza</th>\n",
       "      <th>Bianca</th>\n",
       "      <th>Hawaiian</th>\n",
       "      <th>Americana</th>\n",
       "      <th>Margherita</th>\n",
       "      <th>Dessert_pizza</th>\n",
       "      <th>Thin_crust</th>\n",
       "      <th>Deep_dish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little_pizza_paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>bend</td>\n",
       "      <td>USA</td>\n",
       "      <td>97701</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>pizza_place</td>\n",
       "      <td>bianca_pizza</td>\n",
       "      <td>22.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>little_pizza_paradise</td>\n",
       "      <td>Cascade Village Mall Across From Target</td>\n",
       "      <td>bend</td>\n",
       "      <td>USA</td>\n",
       "      <td>97701</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>pizza_place</td>\n",
       "      <td>cheese_pizza</td>\n",
       "      <td>18.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>USA</td>\n",
       "      <td>90049</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurantbarbakery</td>\n",
       "      <td>pizza_margherita</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>USA</td>\n",
       "      <td>90049</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurantbarbakery</td>\n",
       "      <td>pizza_mushroom</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_brentwood</td>\n",
       "      <td>148 S Barrington Ave</td>\n",
       "      <td>los_angeles</td>\n",
       "      <td>USA</td>\n",
       "      <td>90049</td>\n",
       "      <td>brentwood</td>\n",
       "      <td>american_restaurantbarbakery</td>\n",
       "      <td>pizza_puttenesca</td>\n",
       "      <td>13.00</td>\n",
       "      <td>olives_onions_capers_tomatoes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                  address  \\\n",
       "0  little_pizza_paradise  Cascade Village Mall Across From Target   \n",
       "1  little_pizza_paradise  Cascade Village Mall Across From Target   \n",
       "2          the_brentwood                     148 S Barrington Ave   \n",
       "3          the_brentwood                     148 S Barrington Ave   \n",
       "4          the_brentwood                     148 S Barrington Ave   \n",
       "\n",
       "          city country postcode      state                    categories  \\\n",
       "0         bend     USA    97701     Oregon                   pizza_place   \n",
       "1         bend     USA    97701     Oregon                   pizza_place   \n",
       "2  los_angeles     USA    90049  brentwood  american_restaurantbarbakery   \n",
       "3  los_angeles     USA    90049  brentwood  american_restaurantbarbakery   \n",
       "4  los_angeles     USA    90049  brentwood  american_restaurantbarbakery   \n",
       "\n",
       "          menu item  item value               item description  ...  \\\n",
       "0      bianca_pizza       22.50                            NaN  ...   \n",
       "1      cheese_pizza       18.95                            NaN  ...   \n",
       "2  pizza_margherita       12.00                            NaN  ...   \n",
       "3    pizza_mushroom       13.00                            NaN  ...   \n",
       "4  pizza_puttenesca       13.00  olives_onions_capers_tomatoes  ...   \n",
       "\n",
       "  Vegetarian_pizza  Meat_pizza  Seafood_pizza  Bianca  Hawaiian  Americana  \\\n",
       "0                0           0              0       1         0          0   \n",
       "1                1           0              0       0         0          0   \n",
       "2                1           0              0       0         0          0   \n",
       "3                1           0              0       0         0          0   \n",
       "4                0           0              0       0         0          0   \n",
       "\n",
       "   Margherita  Dessert_pizza  Thin_crust  Deep_dish  \n",
       "0           0              0           0          0  \n",
       "1           0              0           0          1  \n",
       "2           1              0           0          1  \n",
       "3           0              0           0          1  \n",
       "4           0              0           0          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-explanation",
   "metadata": {},
   "source": [
    "Any duplicates can now be dropped using the newly adjusted item name column which has standardised information for both the item and the estblishment that sells it. This will hopefully leave all unique entries in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "accomplished-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping duplicates: (3510, 21)\n",
      "after dropping duplicates: (3161, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"before dropping duplicates: {}\".format(df.shape))\n",
    "df.drop_duplicates(subset = ['item_name'], inplace = True)\n",
    "print(\"after dropping duplicates: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-seventh",
   "metadata": {},
   "source": [
    "# 2.3 Tabular Data to Knowledge Graph (Task RDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-terminal",
   "metadata": {},
   "source": [
    "### Subtask RDF.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "wireless-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising graph and namespace with prefix\n",
    "\n",
    "g = Graph()\n",
    "namespace = 'http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/'\n",
    "jb = Namespace(namespace)\n",
    "g.bind(\"jb\", jb)\n",
    "\n",
    "\n",
    "# adding creator annotation property\n",
    "\n",
    "g.add((URIRef('http://www.semanticweb.org/jake/ontologies/2021/2/jbrown'), jb.Created_by, Literal('Jakob Brown', datatype = RDFS.Literal)))\n",
    "\n",
    "\n",
    "# iterating over the df to create triples\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    \n",
    "# initalising URIs\n",
    "    \n",
    "    # name\n",
    "    establishment = URIRef(namespace+row['name'])\n",
    "    # city\n",
    "    #city = URIRef(namespace+row['city'])\n",
    "    # country\n",
    "    #country = URIRef(namespace+row['country'])\n",
    "    # state\n",
    "    #state = URIRef(namespace+row['state'])\n",
    "    # pizza\n",
    "    pizza = URIRef(namespace+row['item_name'])\n",
    "    \n",
    "    \n",
    "    \n",
    "# adding classes for non-geographic domains\n",
    "    \n",
    "    # establishment\n",
    "    g.add((establishment, RDF.type, jb.Establishment))\n",
    "    \n",
    "    \n",
    "# differentiating the different kinds of pizza on prior encoding, allocating to their respective classes\n",
    "    \n",
    "    if row['Vegetarian_pizza'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Vegetarian_pizza))\n",
    "    if row['Meat_pizza'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Meat_pizza))\n",
    "    if row['Seafood_pizza'] ==1:\n",
    "        g.add((pizza, RDF.type, jb.Seafood_pizza))\n",
    "    if row['Bianca'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Bianca))\n",
    "    if row['Hawaiian'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Hawaiian))\n",
    "    if row['Americana'] ==1:\n",
    "        g.add((pizza, RDF.type, jb.Americana))\n",
    "    if row['Margherita'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Margherita))\n",
    "    if row['Dessert_pizza'] == 1:\n",
    "        g.add((pizza, RDF.type, jb.Dessert_pizza))\n",
    "        \n",
    "    if ((row['Vegetarian_pizza'] == 0) &\n",
    "    (row['Meat_pizza'] == 0) & \n",
    "    (row['Seafood_pizza'] ==0) &\n",
    "    (row['Bianca'] == 0) &\n",
    "    (row['Hawaiian'] == 0) &\n",
    "    (row['Margherita'] == 0) &\n",
    "    (row['Dessert_pizza'] == 0)):\n",
    "        g.add((pizza, RDF.type, jb.Pizza))\n",
    "        \n",
    "        \n",
    "# specifying base type object property\n",
    "    \n",
    "    if row['Thin_crust'] == 1:\n",
    "        g.add((pizza, jb.Has_base, jb.Thin_crust))\n",
    "    if row['Deep_dish'] == 1:\n",
    "        g.add((pizza, jb.Has_base, jb.Deep_dish))\n",
    "        \n",
    "        \n",
    "# other object properties (locations)\n",
    "    \n",
    "    # item to establishment\n",
    "    g.add((pizza, jb.Served_at, establishment))\n",
    "    g.add((establishment, jb.Serves, pizza))\n",
    "    \n",
    "    \n",
    "# adding data properties\n",
    "    \n",
    "    # address\n",
    "    g.add((establishment, jb.Has_address, Literal(row['address'], datatype = RDFS.Literal)))\n",
    "    \n",
    "    # price\n",
    "    if row['item value'] == row['item value']:\n",
    "        g.add((pizza, jb.Has_price, Literal(row['item value'], datatype = XSD.float)))\n",
    "    \n",
    "    # postcode\n",
    "    if row['postcode'] == row['postcode']:\n",
    "        g.add((establishment, jb.Has_postcode, Literal(row['postcode'], datatype = RDFS.Literal)))\n",
    "    \n",
    "    # establishment name\n",
    "    g.add((establishment, jb.Has_name, Literal(row['name'], datatype = RDFS.Literal))) \n",
    "    \n",
    "    # pizza name\n",
    "    g.add((pizza, jb.Has_name, Literal(row['menu item'], datatype = RDFS.Literal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "strange-grave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples at this stage (without reasoning or parsing ontology) are 19952\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of triples at this stage (without reasoning or parsing ontology) are {}\".format(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-injury",
   "metadata": {},
   "source": [
    "### Subtask RDF.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-affair",
   "metadata": {},
   "source": [
    "### For the cells in the columns city, country and state; instead of creating new URIs (e.g., new individuals) for the information in the table cells, reuse an entity URI from DBPedia, Wikidata or Google’s Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "patent-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly adapting the original function provided in lab 6 for non-OOP approach\n",
    "# with the hope of filtering out irrelevant resources that lexical similarity measures may return\n",
    "# by specifying types of information desired e.g. geographical/locations/places/populatedplaces:\n",
    "\n",
    "def getExternalKGURI(name, place_type, attempts = 1):\n",
    "        \n",
    "        \n",
    "        # \"US\" is the only country in the df, so the United States resource can always be returned\n",
    "        if place_type == 'Country':\n",
    "            uri = \"http://dbpedia.org/resource/United_States\"\n",
    "            return uri\n",
    "        else:\n",
    "            # intialising DBpedia lookup\n",
    "            dbpedia = DBpediaLookup() \n",
    "        \n",
    "            # identifying the entities that are similar lexically\n",
    "            entities = dbpedia.getKGEntities(name, 5)\n",
    "            if entities == []: # <-- if there are no results to iterate over\n",
    "                #print(\"no matches found\")\n",
    "                outcome = ''\n",
    "                return outcome\n",
    "        \n",
    "            else:  \n",
    "                current_sim = -1\n",
    "                current_uri=''\n",
    "                for ent in entities:\n",
    "            \n",
    "                    types = ent.types #  isolating the set of \"types\" each resource belongs to\n",
    "            \n",
    "            \n",
    "                    if place_type == \"City\":\n",
    "                \n",
    "                        # filters out returned resources which do not have \"City\" as one of its types\n",
    "                        if 'http://dbpedia.org/ontology/City' in types:\n",
    "                            isub_score = isub(name, ent.label) \n",
    "                            if current_sim < isub_score:\n",
    "                                current_uri = ent.ident\n",
    "                                current_sim = isub_score\n",
    "                                     \n",
    "            \n",
    "            \n",
    "                    elif place_type == \"State\":\n",
    "                \n",
    "                        # filters out returned resources which do not have \"Location\" as one of its types\n",
    "                        # as there did not seem to be a \"state\" type, for US states at least\n",
    "                        if 'http://dbpedia.org/ontology/Place' in types:\n",
    "                            isub_score = isub(name, ent.label) \n",
    "                            if current_sim < isub_score:\n",
    "                                current_uri = ent.ident\n",
    "                                current_sim = isub_score\n",
    "                    \n",
    "                \n",
    "                        \n",
    "            \n",
    "                return current_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "civilian-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all locatable DBpedia resources using the above function\n",
    "\n",
    "    \n",
    "# initialising DBpedia namespace\n",
    "\n",
    "dbp_namespace = \"http://dbpedia.org/resource/\"\n",
    "dbp = Namespace(dbp_namespace)\n",
    "g.bind(\"dbp\", dbp)\n",
    "    \n",
    "    \n",
    "# iterating over the geographical features (city, state, and country)\n",
    "# to check for relevant DBP URIs which can be entwined and added to the present KG:\n",
    "    \n",
    "for idx, row in df.iterrows():\n",
    "        \n",
    "    try:\n",
    "        # city\n",
    "        dbp_URI_city = getExternalKGURI(row['city'], place_type = \"City\")\n",
    "        #print(dbp_URI_city)\n",
    "        if dbp_URI_city != '': # <- if a similar dbpedia uri was found\n",
    "            city = URIRef(dbp_URI_city) # <- assign it as the URI \n",
    "        else:\n",
    "            city = URIRef(namespace+row['city']) # <- else use the name found in the data set with the jb namespace\n",
    "            \n",
    "        # state\n",
    "        dbp_URI_state = getExternalKGURI(row['state'], place_type = \"State\")\n",
    "        #print(dbp_URI_state)\n",
    "        if dbp_URI_state != '': # <- if a similar dbpedia uri was found\n",
    "            state = URIRef(dbp_URI_state) # <- assign it as the URI \n",
    "        else:\n",
    "            state = URIRef(namespace+row['state']) # <- else use the name found in the data set with the jb namespace\n",
    "            \n",
    "\n",
    "        # country    \n",
    "        dbp_URI_country = getExternalKGURI(row['country'], place_type = \"Country\")\n",
    "        #print(dbp_URI_country)\n",
    "        if dbp_URI_country != '': # <- if a similar dbpedia uri was found\n",
    "            country = URIRef(dbp_URI_country) # <- assign it as the URI\n",
    "        else:\n",
    "            country = URIRef(namespace+row['country']) # <- else use the name found in the data set with the jb namespace\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    \n",
    "    # intialising establishment URI to draw object property connections with new DBpedia URIs\n",
    "    establishment = URIRef(namespace+row['name'])\n",
    "\n",
    "        \n",
    "    # adding triples (classes)\n",
    "    g.add((city, RDF.type, jb.City))\n",
    "    g.add((state, RDF.type, jb.State))\n",
    "    g.add((country, RDF.type, jb.Country))\n",
    "    \n",
    "    # adding object properties\n",
    "    g.add((establishment, jb.Is_located_in, city))\n",
    "    g.add((city, jb.Is_located_in, state))\n",
    "    g.add((state, jb.Is_located_in, country))\n",
    "    g.add((country, jb.Has_location, state))\n",
    "    g.add((state, jb.Has_location, city))\n",
    "    g.add((city, jb.Has_location, establishment))\n",
    "    \n",
    "    \n",
    "    # adding data properties \n",
    "    g.add((city, jb.Has_name, Literal(row['city'], datatype = RDFS.Literal)))\n",
    "    g.add((state, jb.Has_name, Literal(row['state'], datatype = RDFS.Literal)))\n",
    "    g.add((country, jb.Has_name, Literal(row['country'], datatype = RDFS.Literal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "lesser-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples at this stage (without reasoning or parsing ontology) are 25704\n",
      "the number of triples at this stage (with parsing ontology) are 26021\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of triples at this stage (without reasoning or parsing ontology) are {}\".format(len(g)))\n",
    "\n",
    "g.serialize('RDF_data.ttl', format = 'ttl')\n",
    "# parsing the ontology\n",
    "g.parse(\"base_ontology.ttl\", format = 'ttl')\n",
    "g.serialize(\"ontology_with_data.ttl\", format = 'ttl')\n",
    "print(\"the number of triples at this stage (with parsing ontology) are {}\".format(len(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-error",
   "metadata": {},
   "source": [
    "# 2.4 SPARQL and Reasoning (Task SPARQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-steal",
   "metadata": {},
   "source": [
    "### Subtask SPARQL.1 Perform reasoning with the created ontology and the generated data. Save the extended graph in turtle format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "rough-fitness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples before reasoning: 26021\n",
      "the number of triples after reasoning: 109005\n",
      "\n",
      "Checking entailments\n",
      "does triple 1 hold? Answer: True\n",
      "does triple 2 hold? Answer: True\n",
      "does triple 3 hold? Answer: True\n",
      "does triple 4 hold? Answer: True\n",
      "Saving extended graph...\n",
      "graph saved\n"
     ]
    }
   ],
   "source": [
    "# defining function implementing SQL ask query\n",
    "def ask_query(g, fact, number):\n",
    "    \n",
    "    qres = g.query(\n",
    "    \n",
    "    \"\"\"ASK {\"\"\" + fact + \"\"\" }\"\"\")\n",
    "    \n",
    "    number = number\n",
    "    for row in qres:\n",
    "        print(\"does triple {} hold? Answer: {}\".format(number, row))\n",
    "        \n",
    "# defining reasoning function to perform reasoning with owlrl semantics, as well as check some specified entailments \n",
    "def perform_reasoning():\n",
    "    \n",
    "    g = Graph()\n",
    "    g.parse('ontology_with_data.ttl', format = 'ttl')\n",
    "    \n",
    "    print(\"the number of triples before reasoning: {}\".format(len(g)))\n",
    "    \n",
    "    # RDFS reasoning using owlrl semantics:\n",
    "    owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=True, datatype_axioms=False).expand(g)\n",
    "\n",
    "    \n",
    "    print(\"the number of triples after reasoning: {}\".format(len(g)))\n",
    "\n",
    "    # intialising some triples to check their entailment:\n",
    "    \n",
    "    t1 = \"jb:Bianca rdfs:subClassOf jb:Specific_pizza .\"\n",
    "    t2 = \"dbp:United_States a jb:Country .\"\n",
    "    t3 = \"jb:Vegetarian_pizza rdfs:subClassOf jb:Pizza .\"\n",
    "    t4 = \"jb:Anchovy rdfs:subClassOf jb:Seafood_topping .\"\n",
    "    \n",
    "    \n",
    "    # checking entailments using SPARQL ASK query:\n",
    "    print(\"\\nChecking entailments\")\n",
    "    ask_query(g, t1, 1)\n",
    "    ask_query(g, t2, 2)\n",
    "    ask_query(g, t3, 3)\n",
    "    ask_query(g, t4, 4)\n",
    "    \n",
    "    # save new extended graph:\n",
    "    print(\"Saving extended graph...\")\n",
    "    g.serialize(destination = 'ontology_with_data_post_reasoning.ttl', format = 'ttl')\n",
    "    print(\"graph saved\")\n",
    "\n",
    "    \n",
    "perform_reasoning() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-penny",
   "metadata": {},
   "source": [
    "### Subtask SPARQL.2 Return all the details of the restaurants that sell pizzas without tomate (i.e. pizza bianca). Return the results as a CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "impaired-pointer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N415d1b66a113493f8cca738833150715 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('ontology_with_data_post_reasoning.ttl', format = 'ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "complimentary-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 18 restaurants that serve a bianca pizza. Details of these establishments have been written to the above csv file.\n"
     ]
    }
   ],
   "source": [
    "qres = g.query(\n",
    "\n",
    "\"\"\" \n",
    "PREFIX jb: <http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?establishment ?address ?postcode (SAMPLE(?city) AS ?city) (SAMPLE(?state) AS ?state) ?country\n",
    "WHERE {\n",
    "?establishment jb:Serves ?pizza .\n",
    "?pizza rdf:type jb:Bianca .\n",
    "?establishment jb:Has_address ?address .\n",
    "?establishment jb:Has_postcode ?postcode .\n",
    "?establishment jb:Is_located_in ?city .\n",
    "?city rdf:type jb:City .\n",
    "?city jb:Is_located_in ?state .\n",
    "?state rdf:type jb:State .\n",
    "?state jb:Is_located_in ?country .\n",
    "?country rdf:type jb:Country .\n",
    "\n",
    "}\n",
    "GROUP BY ?establishment\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# creating and opening csv file\n",
    "f_out = open(\"SPARQL_task2_query_results.csv\",\"w+\")\n",
    "\n",
    "count = 0\n",
    "for row in qres:\n",
    "    \n",
    "    count+=1\n",
    "    \n",
    "    # writing results to csv file\n",
    "    line_str = '\\\"%s\\\",\\\"%s\\\",\\\"%s\\\",\\\"%s\\\",\\\"%s\\\",\\\"%s\\\"\\n' % (row.establishment, row.address, row.postcode, row.city, row.state, row.country)\n",
    "    f_out.write(line_str)\n",
    "            \n",
    "     \n",
    "f_out.close()\n",
    "\n",
    "print(\"There are a total of {} restaurants that serve a bianca pizza. Details of these establishments have\\\n",
    " been written to the above csv file.\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-hepatitis",
   "metadata": {},
   "source": [
    "### Subtask SPARQL.3 Return the average prize of a Margherita pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "killing-oregon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average price, as can be seen above, of a Margherita pizza, is 12.44 USD. This result will not be returned as a CSV file, seeing as there is only one value to return and it can be clearly seen above.\n"
     ]
    }
   ],
   "source": [
    "qres = g.query(\n",
    "\n",
    "\"\"\" \n",
    "PREFIX jb: <http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT (AVG(?price) AS ?avgprice) \n",
    "WHERE\n",
    "{\n",
    "?pizza rdf:type jb:Margherita .\n",
    "?pizza jb:Has_price ?price . }\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# printing result\n",
    "for row in qres:\n",
    "    print(\"The average price, as can be seen above, of a Margherita pizza, is {} USD.\\\n",
    " This result will not be returned as a CSV file, seeing as there is only one value\\\n",
    " to return and it can be clearly seen above.\".format(round(float(row.avgprice), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-police",
   "metadata": {},
   "source": [
    "### Subtask SPARQL.4 Return number of restaurants by city, sorted by state and number of restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cellular-latest",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurants: 2 -city: http://dbpedia.org/resource/Bayonne,_New_Jersey -state: http://dbpedia.org/resource/45th_Street_station_(Hudson–Bergen_Light_Rail)\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Novato,_California -state: http://dbpedia.org/resource/Al-Sanamayn\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Mobile,_Alabama -state: http://dbpedia.org/resource/Alabama\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Montgomery,_Alabama -state: http://dbpedia.org/resource/Alabama\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Fairbanks,_Alaska -state: http://dbpedia.org/resource/Alaska\n",
      "restaurants: 4 -city: http://dbpedia.org/resource/Phoenix,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 3 -city: http://dbpedia.org/resource/Scottsdale,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/cave_creek -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Sedona,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Flagstaff,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Tempe,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/williams -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/lake_havasu_city -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Show_Low,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/prescott_valley -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Prescott,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Chandler,_Arizona -state: http://dbpedia.org/resource/Arizona\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/mechanicsburg -state: http://dbpedia.org/resource/Brandsville,_Missouri\n",
      "restaurants: 4 -city: http://dbpedia.org/resource/Honolulu -state: http://dbpedia.org/resource/British_Hong_Kong\n",
      "restaurants: 1 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/amherst -state: http://dbpedia.org/resource/Brownhelm_Township,_Lorain_County,_Ohio\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Joliet,_Illinois -state: http://dbpedia.org/resource/Burnside,_South_Lanarkshire\n",
      "restaurants: 1 -city: http://dbpedia.org/resource/Cosmopolis,_Washington -state: http://dbpedia.org/resource/Cagliari\n",
      "restaurants: 8 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/los_angeles -state: http://dbpedia.org/resource/California\n",
      "restaurants: 5 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/san_diego -state: http://dbpedia.org/resource/California\n",
      "restaurants: 3 -city: http://dbpedia.org/resource/Corona,_California -state: http://dbpedia.org/resource/California\n",
      "restaurants: 2 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/palm_desert -state: http://dbpedia.org/resource/California\n",
      "restaurants: 2 -city: http://dbpedia.org/resource/Chatsworth,_Georgia -state: http://dbpedia.org/resource/California\n",
      "restaurants: 2 -city: http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/thousand_oaks -state: http://dbpedia.org/resource/California\n",
      "restaurants: 2 -city: http://dbpedia.org/resource/Yucaipa,_California -state: http://dbpedia.org/resource/California\n",
      "restaurants: 2 -city: http://dbpedia.org/resource/Sacramento,_California -state: http://dbpedia.org/resource/California\n"
     ]
    }
   ],
   "source": [
    "qres = g.query(\n",
    "\n",
    "\"\"\" \n",
    "PREFIX jb: <http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT (COUNT(DISTINCT ?restaurant) AS ?count) ?city ?state\n",
    "WHERE {\n",
    "?restaurant jb:Is_located_in ?city .\n",
    "?city rdf:type jb:City .\n",
    "?city jb:Is_located_in ?state .\n",
    "?state rdf:type jb:State .\n",
    "}\n",
    "GROUP BY ?city\n",
    "ORDER BY ?state DESC(?count)\n",
    "\n",
    "\"\"\")\n",
    "    \n",
    "\n",
    "row_limit = 30\n",
    "for row in qres:\n",
    "    \n",
    "    # printing results\n",
    "    if row_limit > 0:\n",
    "        print(\"restaurants: \"+str(row[0])+\" -city: \"+str(row[1])+\" -state: \"+str(row[2]))\n",
    "        row_limit -=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-tucson",
   "metadata": {},
   "source": [
    "The query results in their entirety have been saved to the above csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-newcastle",
   "metadata": {},
   "source": [
    "### Subtask SPARQL.5 Return the list of restaurants with missing postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "white-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There appear to be a total of 12 restaurants that do not have a postcode. Details in the csv file made above\n"
     ]
    }
   ],
   "source": [
    "qres = g.query(\n",
    "\n",
    "\"\"\" \n",
    "PREFIX jb: <http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT DISTINCT ?res\n",
    "WHERE {\n",
    "?res rdf:type jb:Establishment .\n",
    "FILTER NOT EXISTS {?res jb:Has_postcode ?postcode}\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for row in qres:\n",
    "    \n",
    "    count +=1\n",
    "            \n",
    "    \n",
    "\n",
    "print(\"There appear to be a total of {} restaurants that do not have a postcode.\\\n",
    " Details in the csv file made above\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-school",
   "metadata": {},
   "source": [
    "# 2.5 Ontology Alignment (Task OA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-princeton",
   "metadata": {},
   "source": [
    "### Subtask OA.1 Compute equivalences between the entities of the input ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sudden-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ontology loading function from lab 8 code \"AccessEntityLabels.py\"\n",
    "# slightly adapted to suit present needs\n",
    "\n",
    "def getClasses(onto):        \n",
    "    return onto.classes()\n",
    "    \n",
    "def getDataProperties(onto):        \n",
    "    return onto.data_properties()\n",
    "    \n",
    "def getObjectProperties(onto):        \n",
    "    return onto.object_properties()\n",
    "    \n",
    "def getIndividuals(onto):    \n",
    "    return onto.individuals()\n",
    "\n",
    "\n",
    "def getRDFSLabelsForEntity(entity):\n",
    "    #if hasattr(entity, \"label\"):\n",
    "    return entity.label\n",
    "\n",
    "\n",
    "def getRDFSLabelsForEntity(entity):\n",
    "    #if hasattr(entity, \"label\"):\n",
    "    return entity.label    \n",
    "\n",
    "\n",
    "def processClasses(uri):\n",
    "    \n",
    "    #Method from owlready\n",
    "    onto = get_ontology(uri).load()\n",
    "    # number of classes\n",
    "    print(\"Classes in {}: {}\".format(str(uri), len(list(getClasses(onto)))))\n",
    "    \n",
    "    class_list = []\n",
    "    for cls in getClasses(onto): \n",
    "        # class names\n",
    "        print(\"\\t\"+cls.name)\n",
    "        class_list.append(cls.name)\n",
    "    \n",
    "    return class_list\n",
    "\n",
    "def processDataProperties(uri):\n",
    "    \n",
    "    #Method from owlready\n",
    "    onto = get_ontology(uri).load()\n",
    "    # number of data properties\n",
    "    print(\"Data Properties in {}: {}\".format(str(uri), len(list(getDataProperties(onto))))) \n",
    "    \n",
    "    data_properties_list = []\n",
    "    for dp in getDataProperties(onto): \n",
    "        # data property names\n",
    "        print(\"\\t\"+dp.name)\n",
    "        data_properties_list.append(dp.name)\n",
    "    \n",
    "    return data_properties_list\n",
    "\n",
    "def processObjectProperties(uri):\n",
    "    \n",
    "    #Method from owlready\n",
    "    onto = get_ontology(uri).load()\n",
    "    # number of object properties\n",
    "    print(\"Object Properties in {}: {}\".format(str(uri), len(list(getObjectProperties(onto)))))\n",
    "    \n",
    "    object_properties_list = []\n",
    "    for op in getObjectProperties(onto): \n",
    "        # object property names\n",
    "        print(\"\\t\"+op.name)\n",
    "        object_properties_list.append(op.name)\n",
    "    \n",
    "    return object_properties_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "early-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in pizza.owl: 99\n",
      "\tPizza\n",
      "\tPizzaBase\n",
      "\tFood\n",
      "\tSpiciness\n",
      "\tPizzaTopping\n",
      "\tAmerican\n",
      "\tNamedPizza\n",
      "\tMozzarellaTopping\n",
      "\tPeperoniSausageTopping\n",
      "\tTomatoTopping\n",
      "\tAmericanHot\n",
      "\tHotGreenPepperTopping\n",
      "\tJalapenoPepperTopping\n",
      "\tAnchoviesTopping\n",
      "\tFishTopping\n",
      "\tArtichokeTopping\n",
      "\tVegetableTopping\n",
      "\tMild\n",
      "\tAsparagusTopping\n",
      "\tCajun\n",
      "\tOnionTopping\n",
      "\tPeperonataTopping\n",
      "\tPrawnsTopping\n",
      "\tTobascoPepperSauce\n",
      "\tCajunSpiceTopping\n",
      "\tHerbSpiceTopping\n",
      "\tHot\n",
      "\tRosemaryTopping\n",
      "\tCaperTopping\n",
      "\tCapricciosa\n",
      "\tHamTopping\n",
      "\tOliveTopping\n",
      "\tCaprina\n",
      "\tGoatsCheeseTopping\n",
      "\tSundriedTomatoTopping\n",
      "\tCheeseTopping\n",
      "\tCheeseyPizza\n",
      "\tCheeseyVegetableTopping\n",
      "\tChickenTopping\n",
      "\tMeatTopping\n",
      "\tCountry\n",
      "\tDomainConcept\n",
      "\tDeepPanBase\n",
      "\tThinAndCrispyBase\n",
      "\tValuePartition\n",
      "\tFiorentina\n",
      "\tGarlicTopping\n",
      "\tParmesanTopping\n",
      "\tSpinachTopping\n",
      "\tFourCheesesTopping\n",
      "\tFourSeasons\n",
      "\tMushroomTopping\n",
      "\tFruitTopping\n",
      "\tFruttiDiMare\n",
      "\tMixedSeafoodTopping\n",
      "\tMedium\n",
      "\tGiardiniera\n",
      "\tLeekTopping\n",
      "\tPetitPoisTopping\n",
      "\tSlicedTomatoTopping\n",
      "\tGorgonzolaTopping\n",
      "\tGreenPepperTopping\n",
      "\tPepperTopping\n",
      "\tHotSpicedBeefTopping\n",
      "\tIceCream\n",
      "\tInterestingPizza\n",
      "\tLaReine\n",
      "\tMargherita\n",
      "\tMeatyPizza\n",
      "\tMushroom\n",
      "\tNapoletana\n",
      "\tNonVegetarianPizza\n",
      "\tVegetarianPizza\n",
      "\tNutTopping\n",
      "\tParmaHamTopping\n",
      "\tParmense\n",
      "\tPineKernels\n",
      "\tPolloAdAstra\n",
      "\tRedOnionTopping\n",
      "\tSweetPepperTopping\n",
      "\tPrinceCarlo\n",
      "\tQuattroFormaggi\n",
      "\tRealItalianPizza\n",
      "\tRocketTopping\n",
      "\tRosa\n",
      "\tSauceTopping\n",
      "\tSiciliana\n",
      "\tSloppyGiuseppe\n",
      "\tSoho\n",
      "\tSpicyPizza\n",
      "\tSpicyTopping\n",
      "\tSpicyPizzaEquivalent\n",
      "\tSultanaTopping\n",
      "\tThinAndCrispyPizza\n",
      "\tUnclosedPizza\n",
      "\tVegetarianPizzaEquivalent1\n",
      "\tVegetarianTopping\n",
      "\tVegetarianPizzaEquivalent2\n",
      "\tVeneziana\n",
      "Classes in base_ontology.owl: 50\n",
      "\tAmericana\n",
      "\tAnchovy\n",
      "\tBacon\n",
      "\tBeef\n",
      "\tBianca\n",
      "\tCheese_topping\n",
      "\tChicken\n",
      "\tChocolate\n",
      "\tChorizo\n",
      "\tCity\n",
      "\tCountry\n",
      "\tCrab\n",
      "\tDeep_dish\n",
      "\tDessert_pizza\n",
      "\tDessert_topping\n",
      "\tEstablishment\n",
      "\tHam\n",
      "\tHawaiian\n",
      "\tLamb\n",
      "\tMargherita\n",
      "\tMeat_pizza\n",
      "\tMeat_topping\n",
      "\tMiscellaneous_vegetarian_topping\n",
      "\tMozzarella\n",
      "\tMussel\n",
      "\tOyster\n",
      "\tPancetta\n",
      "\tPastrami\n",
      "\tPepperoni\n",
      "\tPineapple\n",
      "\tPizza\n",
      "\tPizza_base\n",
      "\tPizza_topping\n",
      "\tPork\n",
      "\tProsciutto\n",
      "\tSalami\n",
      "\tSalmon\n",
      "\tSardine\n",
      "\tSausage\n",
      "\tSeafood_pizza\n",
      "\tSeafood_topping\n",
      "\tShrimp\n",
      "\tSpecific_pizza\n",
      "\tState\n",
      "\tSteak\n",
      "\tThin_crust\n",
      "\tTuna\n",
      "\tVegetable_topping\n",
      "\tVegetarian_friendly_topping\n",
      "\tVegetarian_pizza\n"
     ]
    }
   ],
   "source": [
    "# creating lists of classes for each ontology\n",
    "pi_uri=\"pizza.owl\"\n",
    "jb_uri = \"base_ontology.owl\"\n",
    "\n",
    "pi_classes = processClasses(pi_uri)\n",
    "jb_classes = processClasses(jb_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "invalid-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to adapt lexical formatting of created ontology entities to that of pizza.owl\n",
    "# e.g. removing underscores between words, and capitalizing the start of each new word\n",
    "def jb2pi_syntax(list):\n",
    "    for idx, each in enumerate(list):\n",
    "        if '_' in each:\n",
    "            words = each.split('_')\n",
    "            for i in range(1, len(words)):\n",
    "                words[i] = words[i].capitalize()\n",
    "            adapted_word = ''.join(words)\n",
    "            list[idx] = adapted_word\n",
    "    return list\n",
    "\n",
    "# defining a function to revert a word from pizza.owl syntax to jb syntax\n",
    "# e.g. only capitalizing the first letter in the entitiy name and placing underscores between each word\n",
    "def pi2jb_syntax(word):\n",
    "    words = re.findall('[A-Z][a-z]*', word)\n",
    "    words = [s.lower() for s in words]\n",
    "    joined = '_'.join(words)\n",
    "    return joined.capitalize()\n",
    "\n",
    "# defining a function to look at the suggested matches yielded for the below lexical matching code\n",
    "# which can then be adapted accordingly to find the best matcher.\n",
    "def evaluate_matcher(dic):\n",
    "    for key, value in dic.items():\n",
    "        print(\"Is {} equal to {}?\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "finished-broadcast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "\n",
    "pizza_owl_namespace = 'http://www.co-ode.org/ontologies/pizza#'\n",
    "jb_namespace = 'http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/'\n",
    "pi = Namespace(pizza_owl_namespace)\n",
    "jb = Namespace(jb_namespace)\n",
    "g.bind(\"pi\", pi)\n",
    "g.bind(\"jb\", jb)\n",
    "\n",
    "\n",
    "# matching classes\n",
    "\n",
    "# modifying the terms in jb_classes to bear better lexical similarity to pizza.owl in order to find more matches\n",
    "jb_classes = jb2pi_syntax(jb_classes)\n",
    "\n",
    "# intialising dictionary to allow evalution of lexical matcher and look at proposed equivalent classes\n",
    "\n",
    "jw = {}\n",
    "match_count = 0\n",
    "\n",
    "# iterating over the classes, creating triples for apparent matches\n",
    "for each in pi_classes:\n",
    "    \n",
    "    # if there is an identical match:\n",
    "    if each in jb_classes:\n",
    "        \n",
    "        pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "        jb_version = URIRef(jb_namespace+str(pi2jb_syntax(each)))\n",
    "        \n",
    "        # adding owl:equivalentClass triple\n",
    "        g.add((pi_version, OWL.equivalentClass, jb_version))\n",
    "        \n",
    "        \n",
    "    \n",
    "    elif ((\"Topping\" in each) & (len(str(each)) > 7)):\n",
    "        if each == \"PizzaTopping\":\n",
    "            \n",
    "            pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "            jb_version = URIRef(jb_namespace+str(\"Pizza_topping\"))\n",
    "            \n",
    "            # adding owl:equivalentClass triple\n",
    "            g.add((pi_version, OWL.equivalentClass, jb_version))\n",
    "            \n",
    "\n",
    "        else:\n",
    "            topping = each.split(\"Topping\")[0]\n",
    "        \n",
    "            if topping in jb_classes:\n",
    "                \n",
    "                pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "                jb_version = URIRef(jb_namespace+str(topping))\n",
    "                \n",
    "                # adding owl:equivalentClass triple\n",
    "                g.add((pi_version, OWL.equivalentClass, jb_version))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # leaving the rest to relatively high standard lexical matching, to prevent mismatches\n",
    "                for word in jb_classes:\n",
    "                    jw_score = Lev.jaro_winkler(topping, word)\n",
    "                    \n",
    "                    # ascertained the best threshold with limited to no mismatches through trial and error\n",
    "                    threshold = 0.9\n",
    "                    \n",
    "                    # filtering out one condition which was not a correct matching of equivalent classes:\n",
    "                    if ((topping == \"Vegetarian\") & (word == \"VegetarianPizza\")):\n",
    "                        continue\n",
    "                    else:\n",
    "                        if jw_score > threshold:\n",
    "                        \n",
    "                            jw[each] = word\n",
    "                        \n",
    "                            pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "                            jb_version = URIRef(jb_namespace+str(pi2jb_syntax(word)))\n",
    "                        \n",
    "                            # adding owl:equivalentClass triple\n",
    "                            g.add((pi_version, OWL.equivalentClass, jb_version))\n",
    "    else: \n",
    "        \n",
    "        # utilising the same lexical matcher for classes that are not toppings\n",
    "        for word in jb_classes:\n",
    "            \n",
    "            jw_score = Lev.jaro_winkler(each, word)\n",
    "            # ascertaining the best threshold with limited to no mismatches through trial and error\n",
    "            threshold = 0.9\n",
    "            \n",
    "            # filtering out one condition which was passing through some mismatched entities as equivalent classes\n",
    "            if ((\"Equivalent\" in each) & (word == \"VegetarianFriendlyTopping\")):\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                if jw_score > threshold:\n",
    "                \n",
    "                    jw[each] = word\n",
    "                    pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "                    jb_version = URIRef(jb_namespace+str(pi2jb_syntax(word)))\n",
    "                    g.add((pi_version, OWL.equivalentClass, jb_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "terminal-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "third-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is American equal to Americana?\n",
      "Is AmericanHot equal to Americana?\n",
      "Is AnchoviesTopping equal to Anchovy?\n",
      "Is PepperTopping equal to Pepperoni?\n",
      "Is MeatyPizza equal to MeatPizza?\n",
      "Is VegetarianPizzaEquivalent1 equal to VegetarianPizza?\n",
      "Is VegetarianTopping equal to VegetarianFriendlyTopping?\n",
      "Is VegetarianPizzaEquivalent2 equal to VegetarianPizza?\n"
     ]
    }
   ],
   "source": [
    "evaluate_matcher(jw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "behavioral-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Properties in pizza.owl: 8\n",
      "\thasBase\n",
      "\thasIngredient\n",
      "\tisBaseOf\n",
      "\thasCountryOfOrigin\n",
      "\tisIngredientOf\n",
      "\thasSpiciness\n",
      "\thasTopping\n",
      "\tisToppingOf\n",
      "Object Properties in base_ontology.owl: 10\n",
      "\tHas_base\n",
      "\tHas_ingredient\n",
      "\tHas_location\n",
      "\tHas_topping\n",
      "\tIs_base_of\n",
      "\tIs_ingredient_of\n",
      "\tIs_located_in\n",
      "\tIs_topping_of\n",
      "\tServed_at\n",
      "\tServes\n"
     ]
    }
   ],
   "source": [
    "# creating list of object properties for each ontology\n",
    "\n",
    "pi_op = processObjectProperties(pi_uri)\n",
    "jb_op = processObjectProperties(jb_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "satellite-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching object properties\n",
    "\n",
    "# defining function to transform ontology entity syntax to match the other, increase likelihood of correct matching\n",
    "# slightly different to the class syntax (no capital letter for first word with properties)\n",
    "def jb2pi_syntax(list):\n",
    "    for idx, each in enumerate(list):\n",
    "        if '_' in each:\n",
    "            words = each.split('_')\n",
    "            for i in range(0, len(words)):\n",
    "                if i < 1:\n",
    "                    words[i] = words[i].lower()\n",
    "                else:\n",
    "                    words[i] = words[i].capitalize()\n",
    "            adapted_word = ''.join(words)\n",
    "            list[idx] = adapted_word\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "polish-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_op = jb2pi_syntax(jb_op)\n",
    "\n",
    "# iterating over pi object properties\n",
    "for each in pi_op:\n",
    "    \n",
    "    # if the same object property is present in jb object properties:\n",
    "    if each in jb_op:\n",
    "        \n",
    "        # create URIs\n",
    "        pi_version = URIRef(pizza_owl_namespace+str(each))\n",
    "        jb_version = URIRef(jb_namespace+str(pi2jb_syntax(each)))\n",
    "        \n",
    "        # adding owl:equivalentProperty triple\n",
    "        g.add((pi_version, OWL.equivalentProperty, jb_version))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "restricted-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(g))\n",
    "g.serialize('ontology_alignments.ttl', format = 'ttl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-contest",
   "metadata": {},
   "source": [
    "### Subtask OA.2 Perform reasoning with (i) the created ontology, (ii) the pizza.owl ontology and (iii) the computed alignment (without the data) and list the number of unsatisfiable classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "colonial-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_reasoning(file, parsing_format = 'ttl'):\n",
    "    \n",
    "    g = Graph()\n",
    "    g.parse(file, format = parsing_format)\n",
    "    \n",
    "    print(\"the number of triples before reasoning: {}\".format(len(g)))\n",
    "    \n",
    "    # RDFS reasoning using owlrl semantics:\n",
    "    owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=True, datatype_axioms=False).expand(g)\n",
    "    \n",
    "    print(\"the number of triples after reasoning: {}\".format(len(g)))\n",
    "    \n",
    "    unsatisfiable_count = 0\n",
    "    for s, p, o in g:\n",
    "        if OWL.Nothing in o:\n",
    "            unsatisfiable_count +=1\n",
    "        if OWL.Nothing in p:\n",
    "            unsatisfiable_count +=1\n",
    "        if OWL.Nothing in s:\n",
    "            unsatisfiable_count +=1\n",
    "    \n",
    "    print(\"the number of unsatisfiable classes in this reasoned ontology are {}\".format(unsatisfiable_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "amber-purple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples before reasoning: 317\n",
      "the number of triples after reasoning: 2579\n",
      "the number of unsatisfiable classes in this reasoned ontology are 113\n"
     ]
    }
   ],
   "source": [
    "# reasoning with i: the created ontology:\n",
    "\n",
    "perform_reasoning('base_ontology.ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "straight-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples before reasoning: 1944\n",
      "the number of triples after reasoning: 13638\n",
      "the number of unsatisfiable classes in this reasoned ontology are 397\n"
     ]
    }
   ],
   "source": [
    "# reasoning with ii: the pizza.owl ontology\n",
    "\n",
    "perform_reasoning('pizza_owl.ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "mediterranean-muslim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples before reasoning: 2287\n",
      "the number of triples after reasoning: 16240\n",
      "the number of unsatisfiable classes in this reasoned ontology are 491\n"
     ]
    }
   ],
   "source": [
    "# reasoning with iii: the aligned ontology\n",
    "\n",
    "g = Graph()\n",
    "g.parse('base_ontology.ttl', format = 'ttl')\n",
    "g.parse('pizza_owl.ttl', format = 'ttl')\n",
    "g.parse('ontology_alignments.ttl', format = 'ttl')\n",
    "\n",
    "print(\"the number of triples before reasoning: {}\".format(len(g)))\n",
    "    \n",
    "# RDFS reasoning using owlrl semantics:\n",
    "owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=True, datatype_axioms=False).expand(g)\n",
    "    \n",
    "print(\"the number of triples after reasoning: {}\".format(len(g)))\n",
    "    \n",
    "unsatisfiable_count = 0\n",
    "for s, p, o in g:\n",
    "    if OWL.Nothing in o:\n",
    "         unsatisfiable_count +=1\n",
    "    if OWL.Nothing in p:\n",
    "         unsatisfiable_count +=1\n",
    "    if OWL.Nothing in s:\n",
    "        unsatisfiable_count +=1\n",
    "    \n",
    "print(\"the number of unsatisfiable classes in this reasoned ontology are {}\".format(unsatisfiable_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-short",
   "metadata": {},
   "source": [
    "reasoning with iv: the aligned ontology, including the RDF data.\n",
    "\n",
    "*for some reason, although there appear to be empty interpretations of things for all 3 previous ontologies,\n",
    "loading them in to protege proved no problem with no unsatisfiables other than ice cream\n",
    "so, Subtask OA.2.b was carried out, querying for the 'MeatyPizzas' using the pizza.owl ontology term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "human-chick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of triples before reasoning: 27991\n",
      "the number of triples after reasoning: 128665\n",
      "the number of unsatisfiable classes in this reasoned ontology are 491\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('RDF_data.ttl', format = 'ttl')\n",
    "g.parse('base_ontology.ttl', format = 'ttl')\n",
    "g.parse('pizza_owl.ttl', format = 'ttl')\n",
    "g.parse('ontology_alignments.ttl', format = 'ttl')\n",
    "\n",
    "g.serialize('aligned_ontology_with_data.ttl', format = 'ttl')\n",
    "\n",
    "print(\"the number of triples before reasoning: {}\".format(len(g)))\n",
    "    \n",
    "# RDFS reasoning using owlrl semantics:\n",
    "owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=True, datatype_axioms=False).expand(g)\n",
    "    \n",
    "print(\"the number of triples after reasoning: {}\".format(len(g)))\n",
    "    \n",
    "unsatisfiable_count = 0\n",
    "for s, p, o in g:\n",
    "    if OWL.Nothing in o:\n",
    "         unsatisfiable_count +=1\n",
    "    if OWL.Nothing in p:\n",
    "         unsatisfiable_count +=1\n",
    "    if OWL.Nothing in s:\n",
    "        unsatisfiable_count +=1\n",
    "    \n",
    "print(\"the number of unsatisfiable classes in this reasoned ontology are {}\".format(unsatisfiable_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-terrorist",
   "metadata": {},
   "source": [
    "### Subtask OA.2.b - Create a query to return the pizzas with type pizza:MeatyPizza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "golden-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of returned meaty pizzas\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/pepperoni_pizza_at_marzanos\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/bbq_chicken_pizza_at_bearnos_pizza\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/sunny_side_up_farm_egg_pizza_at_mc_kitchen\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/chicken_pesto_gourmet_pizza_at_nolita\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/steak_and_cheese_pizza_at_stone_and_paddle\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/hawaiian_pizza_at_good_fellas_pizza\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/chicken_and_broccoli_pizza_medium_at_j__g_restaurant\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/cheesesteak_pizza_at_riccardos_pizza\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/philly_cheesesteak_pizza_at_phat_boyz_new_york_style_pizzeria\n",
      "http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/buffalo_chicken_pizza_at_two_brothers_pizza\n"
     ]
    }
   ],
   "source": [
    "qres = g.query(\n",
    "\"\"\" \n",
    "PREFIX jb: <http://www.semanticweb.org/jake/ontologies/2021/2/jbrown/>\n",
    "PREFIX pizza: <http://www.co-ode.org/ontologies/pizza#>\n",
    "\n",
    "SELECT DISTINCT ?pizzas\n",
    "WHERE {\n",
    "\n",
    "?pizzas rdf:type pizza:MeatyPizza .\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# creating and opening csv file\n",
    "f_out = open(\"OA_meatypizza_query_results.csv\",\"w+\")\n",
    "\n",
    "row_limit = 10\n",
    "print(\"Sample of returned meaty pizzas\")\n",
    "for row in qres:\n",
    "    \n",
    "    # printing results\n",
    "    if row_limit > 0:\n",
    "        print(str(row[0]))\n",
    "        row_limit -=1\n",
    "    \n",
    "    # writing results to csv file\n",
    "    line_str = '\\\"%s\\\"\\n' % (str(row[0]))\n",
    "    f_out.write(line_str)\n",
    "            \n",
    "     \n",
    "f_out.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
